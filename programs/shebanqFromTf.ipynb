{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pipeline](pictures/pictures.003.png)\n",
    "\n",
    "# SHEBANQ from Text-Fabric\n",
    "\n",
    "This notebook assembles data from relevant GitHub repositories of the ETCBC.\n",
    "It selects the data that is needed for the website\n",
    "[SHEBANQ](https://shebanq.ancient-data.org).\n",
    "\n",
    "\n",
    "## Pipeline\n",
    "This is **pipe 2** of the pipeline from ETCBC data to the website SHEBANQ.\n",
    "\n",
    "A run of this pipe produces SHEBANQ data according to a chosen *version*.\n",
    "It should be run whenever there are new or updated data sources present that affect the output data.\n",
    "Since all input data is delivered in GitHub repositories, we have excellent machinery to \n",
    "work with versioning.\n",
    "\n",
    "Which directories the pipe should access for which version is specified in the configuration below.\n",
    "\n",
    "### Core data\n",
    "The core data is what resides in \n",
    "the GitHub repo [BHSA](https://github.com/ETCBC/bhsa) in directory `tf`.\n",
    "\n",
    "This data will be converted by notebook `coreData` in its `programs` directory.\n",
    "\n",
    "The result of this action will be an updated Text-Fabric resource in its \n",
    "`tf` directory, under the chosen *version*.\n",
    "\n",
    "### Additional data\n",
    "\n",
    "The pipe will try to load any text-fabric data features found in the `tf` subdirectories\n",
    "of the designated additional repos.\n",
    "It will descend one level deeper, according to the chosen *version*.\n",
    "\n",
    "### Resulting data\n",
    "The resulting data will be delivered in the `shebanq` subdirectory of the core repo `bhsa`, \n",
    "and then under the chosen *version* subdirectory.\n",
    "\n",
    "The resulting data consists of three parts:\n",
    "\n",
    "* One big MQL file, containing the core data plus **all** additions: `bhsa-xx.mql`.\n",
    "  It will be bzipped.\n",
    "* **not yet implemented** \n",
    "  A subdirectory `mysql` with database tables, containing everything SHEBANQ needs to construct its pages.\n",
    "* **not yet implemented**\n",
    "  A subdirectory `annotations`, containing bulk-uploadable annotation sets, that SHEBANQ can show in notes view,\n",
    "  between the clause atoms of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os,sys,collections\n",
    "from pipeline import webPipeline, copyServer\n",
    "from tf.fabric import Fabric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if 'SCRIPT' not in locals(): \n",
    "    SCRIPT = False\n",
    "    VERSION = '2017'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = dict(\n",
    "    repoOrder = '''\n",
    "        bhsa\n",
    "        phono\n",
    "        valence\n",
    "        parallels\n",
    "    ''',\n",
    ")\n",
    "user = 'dirkr'\n",
    "server = 'clarin11.dans.knaw.nl'\n",
    "remoteDir = '/home/dirkr/shebanq-install'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##############################################################################################\n",
      "#                                                                                            #\n",
      "#       0.00s Aggregate MQL for version 2017                                                 #\n",
      "#                                                                                            #\n",
      "##############################################################################################\n",
      "\n",
      "|       0.00s \tAlready up to date\n",
      "|       0.00s \tbzipping /Users/dirk/github/etcbc/bhsa/_temp/2017/shebanq/shebanq_etcbc2017.mql\n",
      "|       0.00s \tand delivering as /Users/dirk/github/etcbc/bhsa/shebanq/2017/shebanq_etcbc2017.mql.bz2 ...\n",
      "|       0.00s \tNOTE: Using existing bzipped file which is newer than unzipped one\n",
      "|       0.00s \tDone\n",
      "\n",
      "##############################################################################################\n",
      "#                                                                                            #\n",
      "#       0.00s Create Mysql passage db for version 2017                                       #\n",
      "#                                                                                            #\n",
      "##############################################################################################\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------\n",
      "-       0.00s Run notebook [pipeline/passageFromTf] with parameters:                         -\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "|       0.00s \tVERSION              = 2017\n",
      "|       1.74s \tDestination /Users/dirk/github/etcbc/bhsa/shebanq/2017/shebanq_passage2017.sql.gz does not exist\n",
      "..............................................................................................\n",
      ".       1.74s Loading relevant features                                                      .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 3.0.9\n",
      "Api reference : https://github.com/Dans-labs/text-fabric/wiki/Api\n",
      "Tutorial      : https://github.com/Dans-labs/text-fabric/blob/master/docs/tutorial.ipynb\n",
      "Example data  : https://github.com/Dans-labs/text-fabric-data\n",
      "\n",
      "117 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.01s B book                 from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.01s B chapter              from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.01s B verse                from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.15s B g_cons               from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.20s B g_cons_utf8          from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.15s B g_lex                from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.20s B g_word               from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.25s B g_word_utf8          from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.24s B lex_utf8             from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.26s B phono                from /Users/dirk/github/etcbc/phono/tf/2017\n",
      "   |     0.08s B phono_trailer        from /Users/dirk/github/etcbc/phono/tf/2017\n",
      "   |     0.00s B qere_trailer_utf8    from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.00s B qere_utf8            from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.10s B trailer_utf8         from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.11s B language             from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.13s B lex                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.13s B sp                   from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.12s B pdp                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.12s B ls                   from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.01s B voc_lex              from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.01s B voc_lex_utf8         from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.13s B vt                   from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.17s B vs                   from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.12s B gn                   from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.13s B nu                   from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.14s B ps                   from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.10s B st                   from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.11s B nme                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.13s B pfm                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.13s B prs                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.13s B uvf                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.12s B vbe                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.12s B vbs                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.01s B gloss                from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.00s B nametype             from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.00s B root                 from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.03s B pargr                from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.08s B function             from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.21s B typ                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.26s B rela                 from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.04s B txt                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.17s B det                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.03s B code                 from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.02s B tab                  from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.23s B number               from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.09s B freq_lex             from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.09s B freq_occ             from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.08s B rank_lex             from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.08s B rank_occ             from /Users/dirk/github/etcbc/bhsa/tf/2017\n",
      "   |     0.00s Feature overview: 110 for nodes; 5 for edges; 2 configs; 7 computed\n",
      "  8.98s All features loaded/computed - for details use loadLog()\n",
      "|         12s Lexicon arc has   708 entries\n",
      "|         12s Lexicon hbo has  8525 entries\n",
      "|         12s Building qere index\n",
      "|         12s Found 1892 qeres\n",
      "|         12s Building para index\n",
      "|         12s Found para information for 90669 clause_atoms\n",
      "..............................................................................................\n",
      ".         12s Fill the tables ...                                                            .\n",
      "..............................................................................................\n",
      "|         20s OK    book           name           : max size =      13 of    32\n",
      "|         20s OK    clause_atom    text           : max size =     271 of   512\n",
      "|         20s OK    lexicon        entry          : max size =      14 of    32\n",
      "|         20s OK    lexicon        entry_heb      : max size =      15 of    32\n",
      "|         20s OK    lexicon        entryid        : max size =      15 of    32\n",
      "|         20s OK    lexicon        entryid_heb    : max size =      16 of    32\n",
      "|         20s OK    lexicon        g_entry        : max size =      24 of    32\n",
      "|         20s OK    lexicon        g_entry_heb    : max size =      23 of    32\n",
      "|         20s OK    lexicon        gloss          : max size =      27 of    32\n",
      "|         20s OK    lexicon        id             : max size =      16 of    32\n",
      "|         20s OK    lexicon        lan            : max size =       3 of     4\n",
      "|         20s OK    lexicon        nametype       : max size =      14 of    16\n",
      "|         20s OK    lexicon        pos            : max size =       4 of     8\n",
      "|         20s OK    lexicon        root           : max size =      11 of    32\n",
      "|         20s OK    lexicon        subpos         : max size =       4 of     8\n",
      "|         20s OK    verse          text           : max size =     449 of  1024\n",
      "|         20s OK    verse          xml            : max size =    2869 of  4096\n",
      "|         20s Done\n",
      "All lexemes have been found in the lexicon\n",
      "..............................................................................................\n",
      ".         20s Generating word info data ...                                                  .\n",
      "..............................................................................................\n",
      "|         20s \tGenesis\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|         34s \tExodus\n",
      "|         46s \tLeviticus\n",
      "|         54s \tNumeri\n",
      "|      1m 05s \tDeuteronomium\n",
      "|      1m 15s \tJosua\n",
      "|      1m 22s \tJudices\n",
      "|      1m 29s \tSamuel_I\n",
      "|      1m 38s \tSamuel_II\n",
      "|      1m 46s \tReges_I\n",
      "|      1m 55s \tReges_II\n",
      "|      2m 03s \tJesaia\n",
      "|      2m 15s \tJeremia\n",
      "|      2m 29s \tEzechiel\n",
      "|      2m 42s \tHosea\n",
      "|      2m 43s \tJoel\n",
      "|      2m 44s \tAmos\n",
      "|      2m 45s \tObadia\n",
      "|      2m 46s \tJona\n",
      "|      2m 46s \tMicha\n",
      "|      2m 47s \tNahum\n",
      "|      2m 47s \tHabakuk\n",
      "|      2m 48s \tZephania\n",
      "|      2m 48s \tHaggai\n",
      "|      2m 49s \tSacharia\n",
      "|      2m 51s \tMaleachi\n",
      "|      2m 52s \tPsalmi\n",
      "|      3m 04s \tIob\n",
      "|      3m 10s \tProverbia\n",
      "|      3m 15s \tRuth\n",
      "|      3m 15s \tCanticum\n",
      "|      3m 16s \tEcclesiastes\n",
      "|      3m 19s \tThreni\n",
      "|      3m 20s \tEsther\n",
      "|      3m 22s \tDaniel\n",
      "|      3m 25s \tEsra\n",
      "|      3m 28s \tNehemia\n",
      "|      3m 32s \tChronica_I\n",
      "|      3m 39s \tChronica_II\n",
      "|      3m 48s Done\n",
      "OK    word           word_heb            : max size =      28 of    32\n",
      "OK    word           word_ktv            : max size =      15 of    32\n",
      "OK    word           word_vlex           : max size =      23 of    32\n",
      "OK    word           word_clex           : max size =      15 of    32\n",
      "OK    word           word_tran           : max size =      28 of    32\n",
      "OK    word           word_phono          : max size =      23 of    32\n",
      "OK    word           word_phono_sep      : max size =       3 of     8\n",
      "OK    word           word_lex            : max size =      15 of    32\n",
      "OK    word           word_glex           : max size =      24 of    32\n",
      "OK    word           word_gloss          : max size =      27 of    32\n",
      "OK    word           word_lang           : max size =       3 of     8\n",
      "OK    word           word_pos            : max size =       4 of     8\n",
      "OK    word           word_pdp            : max size =       4 of     8\n",
      "OK    word           word_subpos         : max size =       4 of     8\n",
      "OK    word           word_nmtp           : max size =      14 of    32\n",
      "OK    word           word_tense          : max size =       4 of     8\n",
      "OK    word           word_stem           : max size =       4 of     8\n",
      "OK    word           word_gender         : max size =       7 of     8\n",
      "OK    word           word_gnumber        : max size =       7 of     8\n",
      "OK    word           word_person         : max size =       7 of     8\n",
      "OK    word           word_state          : max size =       2 of     8\n",
      "OK    word           word_nme            : max size =       6 of     8\n",
      "OK    word           word_pfm            : max size =       6 of     8\n",
      "OK    word           word_prs            : max size =       6 of     8\n",
      "OK    word           word_uvf            : max size =       6 of     8\n",
      "OK    word           word_vbe            : max size =       3 of     8\n",
      "OK    word           word_vbs            : max size =       6 of     8\n",
      "OK    word           subphrase_border    : max size =       8 of    16\n",
      "OK    word           subphrase_number    : max size =      14 of    32\n",
      "OK    word           subphrase_rela      : max size =       3 of     8\n",
      "OK    word           phrase_border       : max size =       5 of     8\n",
      "OK    word           phrase_atom_rela    : max size =       4 of     8\n",
      "OK    word           phrase_function     : max size =       4 of     8\n",
      "OK    word           phrase_rela         : max size =       4 of     8\n",
      "OK    word           phrase_typ          : max size =       4 of     8\n",
      "OK    word           phrase_det          : max size =       3 of     8\n",
      "OK    word           clause_border       : max size =       5 of     8\n",
      "OK    word           clause_atom_pargr   : max size =      39 of    64\n",
      "OK    word           clause_rela         : max size =       4 of     8\n",
      "OK    word           clause_typ          : max size =       4 of     8\n",
      "OK    word           clause_txt          : max size =       7 of     8\n",
      "OK    word           sentence_border     : max size =       5 of     8\n",
      "..............................................................................................\n",
      ".      3m 48s Generating SQL ...                                                             .\n",
      "..............................................................................................\n",
      "|      3m 48s \ttable book\n",
      "|      3m 48s \ttable chapter\n",
      "|      3m 48s \ttable verse\n",
      "|      3m 49s \ttable clause_atom\n",
      "|      3m 49s \ttable lexicon\n",
      "|      3m 49s \ttable word\n",
      "|      3m 49s \ttable word_verse\n",
      "|      3m 50s Done\n",
      "|      4m 19s SUCCESS passageFromTf\n",
      "\n",
      "----------------------------------------------------------------------------------------------\n",
      "-      4m 19s SUCCES [pipeline/passageFromTf]                                                -\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "|      4m 19s \tDone\n"
     ]
    }
   ],
   "source": [
    "good = webPipeline(pipeline, version=VERSION, force=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#good = True\n",
    "if False and good:\n",
    "    good = importLocal(pipeline, version=VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##############################################################################################\n",
      "#                                                                                            #\n",
      "#      4m 19s Sending MQL and passage databases for version 2017 to server                   #\n",
      "#                                                                                            #\n",
      "##############################################################################################\n",
      "\n",
      "|      4m 19s \tshebanq_etcbc2017.mql.bz2\n",
      "|      4m 19s \tscp /Users/dirk/github/etcbc/bhsa/shebanq/2017/shebanq_etcbc2017.mql.bz2 dirkr@clarin11.dans.knaw.nl:/home/dirkr/shebanq-install/shebanq_etcbc2017.mql.bz2\n",
      "|      4m 31s \tdone\n",
      "|      4m 31s \tshebanq_passage2017.sql.gz\n",
      "|      4m 31s \tscp /Users/dirk/github/etcbc/bhsa/shebanq/2017/shebanq_passage2017.sql.gz dirkr@clarin11.dans.knaw.nl:/home/dirkr/shebanq-install/shebanq_passage2017.sql.gz\n",
      "|      4m 44s \tdone\n"
     ]
    }
   ],
   "source": [
    "#good = True\n",
    "if good:\n",
    "    good = copyServer(pipeline, user, server, remoteDir, version=VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
