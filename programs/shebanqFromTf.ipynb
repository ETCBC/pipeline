{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pipeline](pictures/pictures.003.png)\n",
    "\n",
    "# SHEBANQ from Text-Fabric\n",
    "\n",
    "This notebook assembles data from relevant GitHub repositories of the ETCBC.\n",
    "It selects the data that is needed for the website\n",
    "[SHEBANQ](https://shebanq.ancient-data.org).\n",
    "\n",
    "\n",
    "## Pipeline\n",
    "This is **pipe 2** of the pipeline from ETCBC data to the website SHEBANQ.\n",
    "\n",
    "A run of this pipe produces SHEBANQ data according to a chosen *version*.\n",
    "It should be run whenever there are new or updated data sources present that affect the output data.\n",
    "Since all input data is delivered in GitHub repositories, we have excellent machinery to\n",
    "work with versioning.\n",
    "\n",
    "Which directories the pipe should access for which version is specified in the configuration below.\n",
    "\n",
    "### Core data\n",
    "The core data is what resides in\n",
    "the GitHub repo [BHSA](https://github.com/ETCBC/bhsa) in directory `tf`.\n",
    "\n",
    "This data will be converted by notebook `coreData` in its `programs` directory.\n",
    "\n",
    "The result of this action will be an updated Text-Fabric resource in its\n",
    "`tf` directory, under the chosen *version*.\n",
    "\n",
    "### Additional data\n",
    "\n",
    "The pipe will try to load any text-fabric data features found in the `tf` subdirectories\n",
    "of the designated additional repos.\n",
    "It will descend one level deeper, according to the chosen *version*.\n",
    "\n",
    "### Resulting data\n",
    "The resulting data will be delivered in the `shebanq` subdirectory of the core repo `bhsa`,\n",
    "and then under the chosen *version* subdirectory.\n",
    "\n",
    "The resulting data consists of three parts:\n",
    "\n",
    "* One big MQL file, containing the core data plus **all** additions: `bhsa-xx.mql`.\n",
    "  It will be bzipped.\n",
    "* An `sql` with database tables, containing everything SHEBANQ needs to construct its pages.\n",
    "* **not yet implemented**\n",
    "  A subdirectory `annotations`, containing bulk-uploadable annotation sets, that SHEBANQ can show in notes view,\n",
    "  between the clause atoms of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import webPipeline, importLocal, copyServer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"SCRIPT\" not in locals():\n",
    "    SCRIPT = False\n",
    "    VERSIONS = [\"2021\"]\n",
    "    KINDS = {\"mql\", \"mysql\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = dict(\n",
    "    repoOrder=\"\"\"\n",
    "        bhsa\n",
    "        phono\n",
    "        valence\n",
    "        parallels\n",
    "    \"\"\",\n",
    ")\n",
    "user = \"dirkr\"\n",
    "server = \"clarin11.dans.knaw.nl\"\n",
    "remoteDir = \"/home/dirkr/shebanq-install\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##############################################################################################\n",
      "#                                                                                            #\n",
      "#       0.00s Aggregate MQL for version 2021                                                 #\n",
      "#                                                                                            #\n",
      "##############################################################################################\n",
      "\n",
      "|       0.00s \tWork to do because you forced me to!\n",
      "\n",
      "##############################################################################################\n",
      "#                                                                                            #\n",
      "#       0.00s Using TF to make an MQL export                                                 #\n",
      "#                                                                                            #\n",
      "##############################################################################################\n",
      "\n",
      "This is Text-Fabric 9.0.2\n",
      "Api reference : https://annotation.github.io/text-fabric/tf/cheatsheet.html\n",
      "\n",
      "130 features found and 0 ignored\n",
      "  0.00s Checking features of dataset shebanq_etcbc2021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "   |     0.00s feature \"book@am\" => \"book_am\"\n",
      "   |     0.00s feature \"book@ar\" => \"book_ar\"\n",
      "   |     0.00s feature \"book@bn\" => \"book_bn\"\n",
      "   |     0.00s feature \"book@da\" => \"book_da\"\n",
      "   |     0.00s feature \"book@de\" => \"book_de\"\n",
      "   |     0.00s feature \"book@el\" => \"book_el\"\n",
      "   |     0.00s feature \"book@en\" => \"book_en\"\n",
      "   |     0.00s feature \"book@es\" => \"book_es\"\n",
      "   |     0.00s feature \"book@fa\" => \"book_fa\"\n",
      "   |     0.00s feature \"book@fr\" => \"book_fr\"\n",
      "   |     0.00s feature \"book@he\" => \"book_he\"\n",
      "   |     0.00s feature \"book@hi\" => \"book_hi\"\n",
      "   |     0.00s feature \"book@id\" => \"book_id\"\n",
      "   |     0.00s feature \"book@ja\" => \"book_ja\"\n",
      "   |     0.00s feature \"book@ko\" => \"book_ko\"\n",
      "   |     0.00s feature \"book@la\" => \"book_la\"\n",
      "   |     0.00s feature \"book@nl\" => \"book_nl\"\n",
      "   |     0.00s feature \"book@pa\" => \"book_pa\"\n",
      "   |     0.00s feature \"book@pt\" => \"book_pt\"\n",
      "   |     0.00s feature \"book@ru\" => \"book_ru\"\n",
      "   |     0.00s feature \"book@sw\" => \"book_sw\"\n",
      "   |     0.00s feature \"book@syc\" => \"book_syc\"\n",
      "   |     0.00s feature \"book@tr\" => \"book_tr\"\n",
      "   |     0.00s feature \"book@ur\" => \"book_ur\"\n",
      "   |     0.00s feature \"book@yo\" => \"book_yo\"\n",
      "   |     0.00s feature \"book@zh\" => \"book_zh\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.71s 126 features to export to MQL ...\n",
      "  0.73s Loading 126 features\n",
      "  6.11s Writing enumerations\n",
      "\tbook_am        :   39 values, 39 not a name, e.g. «መኃልየ_መኃልይ_ዘሰሎሞን»\n",
      "\tbook_ar        :   39 values, 39 not a name, e.g. «1_اخبار»\n",
      "\tbook_bn        :   39 values, 39 not a name, e.g. «আদিপুস্তক»\n",
      "\tbook_da        :   39 values, 13 not a name, e.g. «1.Kongebog»\n",
      "\tbook_de        :   39 values, 7 not a name, e.g. «1_Chronik»\n",
      "\tbook_el        :   39 values, 39 not a name, e.g. «Άσμα_Ασμάτων»\n",
      "\tbook_en        :   39 values, 6 not a name, e.g. «1_Chronicles»\n",
      "\tbook_es        :   39 values, 22 not a name, e.g. «1_Crónicas»\n",
      "\tbook_fa        :   39 values, 39 not a name, e.g. «استر»\n",
      "\tbook_fr        :   39 values, 19 not a name, e.g. «1_Chroniques»\n",
      "\tbook_he        :   39 values, 39 not a name, e.g. «איוב»\n",
      "\tbook_hi        :   39 values, 39 not a name, e.g. «1_इतिहास»\n",
      "\tbook_id        :   39 values, 7 not a name, e.g. «1_Raja-raja»\n",
      "\tbook_ja        :   39 values, 39 not a name, e.g. «アモス書»\n",
      "\tbook_ko        :   39 values, 39 not a name, e.g. «나훔»\n",
      "\tbook_nl        :   39 values, 8 not a name, e.g. «1_Koningen»\n",
      "\tbook_pa        :   39 values, 39 not a name, e.g. «1_ਇਤਹਾਸ»\n",
      "\tbook_pt        :   39 values, 21 not a name, e.g. «1_Crônicas»\n",
      "\tbook_ru        :   39 values, 39 not a name, e.g. «1-я_Паралипоменон»\n",
      "\tbook_sw        :   39 values, 6 not a name, e.g. «1_Mambo_ya_Nyakati»\n",
      "\tbook_syc       :   39 values, 39 not a name, e.g. «ܐ_ܒܪܝܡܝܢ»\n",
      "\tbook_tr        :   39 values, 16 not a name, e.g. «1_Krallar»\n",
      "\tbook_ur        :   39 values, 39 not a name, e.g. «احبار»\n",
      "\tbook_yo        :   39 values, 8 not a name, e.g. «Amọsi»\n",
      "\tbook_zh        :   38 values, 37 not a name, e.g. «以斯帖记»\n",
      "\tcfunction      :   26 values, 1 not a name, e.g. «»\n",
      "\tdomain         :    4 values, 1 not a name, e.g. «?»\n",
      "\tf_correction   :    1 values, 1 not a name, e.g. «»\n",
      "\tg_nme          :  108 values, 108 not a name, e.g. «»\n",
      "\tg_nme_utf8     :  106 values, 106 not a name, e.g. «»\n",
      "\tg_pfm          :   87 values, 87 not a name, e.g. «»\n",
      "\tg_pfm_utf8     :   86 values, 86 not a name, e.g. «»\n",
      "\tg_prs          :  127 values, 127 not a name, e.g. «»\n",
      "\tg_prs_utf8     :  126 values, 126 not a name, e.g. «»\n",
      "\tg_uvf          :   19 values, 19 not a name, e.g. «»\n",
      "\tg_uvf_utf8     :   17 values, 17 not a name, e.g. «»\n",
      "\tg_vbe          :  101 values, 101 not a name, e.g. «»\n",
      "\tg_vbe_utf8     :   97 values, 97 not a name, e.g. «»\n",
      "\tg_vbs          :   66 values, 66 not a name, e.g. «»\n",
      "\tg_vbs_utf8     :   65 values, 65 not a name, e.g. «»\n",
      "\tgrammatical    :   11 values, 2 not a name, e.g. «»\n",
      "\tinstruction    :   35 values, 20 not a name, e.g. «.#»\n",
      "\tlexical        :    4 values, 1 not a name, e.g. «»\n",
      "\tnametype       :   10 values, 5 not a name, e.g. «gens,topo»\n",
      "\tnme            :   20 values, 7 not a name, e.g. «»\n",
      "\toriginal       :    2 values, 2 not a name, e.g. «»\n",
      "\tpfm            :   11 values, 4 not a name, e.g. «»\n",
      "\tphono_trailer  :    4 values, 4 not a name, e.g. «»\n",
      "\tprs            :   22 values, 4 not a name, e.g. «H=»\n",
      "\tqere_trailer   :    5 values, 5 not a name, e.g. «»\n",
      "\tqere_trailer_utf8:    5 values, 5 not a name, e.g. «»\n",
      "\troot           :  757 values, 212 not a name, e.g. «<Assyrian>»\n",
      "\ts_manual       :    1 values, 1 not a name, e.g. «»\n",
      "\tsemantic       :    5 values, 1 not a name, e.g. «»\n",
      "\tsense          :   15 values, 11 not a name, e.g. «--»\n",
      "\ttrailer        :   13 values, 13 not a name, e.g. «»\n",
      "\ttrailer_utf8   :   13 values, 13 not a name, e.g. «»\n",
      "\ttxt            :  136 values, 59 not a name, e.g. «?»\n",
      "\tuvf            :    6 values, 1 not a name, e.g. «>»\n",
      "\tvbe            :   19 values, 6 not a name, e.g. «»\n",
      "\tvbs            :   11 values, 3 not a name, e.g. «>»\n",
      "   |     0.76s Writing an all-in-one enum with  237 values\n",
      "  6.83s Mapping 126 features onto 13 object types\n",
      "    11s Writing 126 features as data in 13 object types\n",
      "   |     0.00s word data ...\n",
      "   |      |     2.84s batch of size               47.0MB with   50000 of   50000 words\n",
      "   |      |     5.71s batch of size               47.0MB with   50000 of  100000 words\n",
      "   |      |     8.64s batch of size               47.2MB with   50000 of  150000 words\n",
      "   |      |       12s batch of size               47.2MB with   50000 of  200000 words\n",
      "   |      |       15s batch of size               47.4MB with   50000 of  250000 words\n",
      "   |      |       17s batch of size               47.4MB with   50000 of  300000 words\n",
      "   |      |       20s batch of size               47.5MB with   50000 of  350000 words\n",
      "   |      |       23s batch of size               47.4MB with   50000 of  400000 words\n",
      "   |      |       25s batch of size               25.2MB with   26590 of  426590 words\n",
      "   |       25s word data: 426590 objects\n",
      "   |     0.00s subphrase data ...\n",
      "   |      |     0.30s batch of size                5.7MB with   50000 of   50000 subphrases\n",
      "   |      |     0.59s batch of size                5.7MB with   50000 of  100000 subphrases\n",
      "   |      |     0.67s batch of size                1.6MB with   13850 of  113850 subphrases\n",
      "   |     0.67s subphrase data: 113850 objects\n",
      "   |     0.00s phrase_atom data ...\n",
      "   |      |     0.51s batch of size                9.6MB with   50000 of   50000 phrase_atoms\n",
      "   |      |     1.02s batch of size                9.7MB with   50000 of  100000 phrase_atoms\n",
      "   |      |     1.52s batch of size                9.7MB with   50000 of  150000 phrase_atoms\n",
      "   |      |     2.02s batch of size                9.7MB with   50000 of  200000 phrase_atoms\n",
      "   |      |     2.52s batch of size                9.7MB with   50000 of  250000 phrase_atoms\n",
      "   |      |     2.70s batch of size                3.4MB with   17532 of  267532 phrase_atoms\n",
      "   |     2.70s phrase_atom data: 267532 objects\n",
      "   |     0.00s phrase data ...\n",
      "   |      |     0.78s batch of size               14.6MB with   50000 of   50000 phrases\n",
      "   |      |     1.55s batch of size               14.9MB with   50000 of  100000 phrases\n",
      "   |      |     2.32s batch of size               14.8MB with   50000 of  150000 phrases\n",
      "   |      |     3.08s batch of size               14.5MB with   50000 of  200000 phrases\n",
      "   |      |     3.83s batch of size               14.3MB with   50000 of  250000 phrases\n",
      "   |      |     3.88s batch of size              977.6KB with    3203 of  253203 phrases\n",
      "   |     3.89s phrase data: 253203 objects\n",
      "   |     0.00s clause_atom data ...\n",
      "   |      |     0.69s batch of size               12.0MB with   50000 of   50000 clause_atoms\n",
      "   |      |     1.26s batch of size                9.8MB with   40704 of   90704 clause_atoms\n",
      "   |     1.26s clause_atom data: 90704 objects\n",
      "   |     0.00s clause data ...\n",
      "   |      |     0.67s batch of size               11.5MB with   50000 of   50000 clauses\n",
      "   |      |     1.17s batch of size                8.7MB with   38131 of   88131 clauses\n",
      "   |     1.17s clause data: 88131 objects\n",
      "   |     0.00s sentence_atom data ...\n",
      "   |      |     0.29s batch of size                5.3MB with   50000 of   50000 sentence_atoms\n",
      "   |      |     0.37s batch of size                1.6MB with   14514 of   64514 sentence_atoms\n",
      "   |     0.38s sentence_atom data: 64514 objects\n",
      "   |     0.00s sentence data ...\n",
      "   |      |     0.22s batch of size                3.8MB with   50000 of   50000 sentences\n",
      "   |      |     0.28s batch of size                1.1MB with   13717 of   63717 sentences\n",
      "   |     0.28s sentence data: 63717 objects\n",
      "   |     0.00s half_verse data ...\n",
      "   |      |     0.22s batch of size                3.4MB with   45179 of   45179 half_verses\n",
      "   |     0.22s half_verse data: 45179 objects\n",
      "   |     0.00s verse data ...\n",
      "   |      |     0.22s batch of size                3.6MB with   23213 of   23213 verses\n",
      "   |     0.22s verse data: 23213 objects\n",
      "   |     0.00s lex data ...\n",
      "   |      |     0.34s batch of size                4.5MB with    9230 of    9230 lexs\n",
      "   |     0.34s lex data: 9230 objects\n",
      "   |     0.00s chapter data ...\n",
      "   |      |     0.04s batch of size               86.6KB with     929 of     929 chapters\n",
      "   |     0.04s chapter data: 929 objects\n",
      "   |     0.00s book data ...\n",
      "   |      |     0.04s batch of size               27.3KB with      39 of      39 books\n",
      "   |     0.04s book data: 39 objects\n",
      "    48s Done\n",
      "|         48s \tbzipping /Users/dirk/github/etcbc/bhsa/_temp/2021/shebanq/shebanq_etcbc2021.mql\n",
      "|         48s \tand delivering as /Users/dirk/github/etcbc/bhsa/shebanq/2021/shebanq_etcbc2021.mql.bz2 ...\n",
      "|      2m 11s \tDone\n",
      "\n",
      "##############################################################################################\n",
      "#                                                                                            #\n",
      "#      2m 11s Create Mysql passage db for version 2021                                       #\n",
      "#                                                                                            #\n",
      "##############################################################################################\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------\n",
      "-      2m 11s Run notebook [pipeline/passageFromTf] with parameters:                         -\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "|      2m 11s \tVERSION              = 2021\n",
      "|      2m 11s \tDestination /Users/dirk/github/etcbc/bhsa/shebanq/2021/shebanq_passage2021.sql.gz does not exist\n",
      "..............................................................................................\n",
      ".      2m 11s Loading relevant features                                                      .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 9.0.2\n",
      "Api reference : https://annotation.github.io/text-fabric/tf/cheatsheet.html\n",
      "\n",
      "117 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s Dataset without structure sections in otext:no structure functions in the T-API\n",
      "  4.89s All features loaded/computed - for details use TF.isLoaded()\n",
      "|      2m 17s Lexicon arc has   708 entries\n",
      "|      2m 17s Lexicon hbo has  8522 entries\n",
      "|      2m 17s Building qere index\n",
      "|      2m 17s Found 1892 qeres\n",
      "|      2m 17s Building para index\n",
      "|      2m 17s Found para information for 90704 clause_atoms\n",
      "..............................................................................................\n",
      ".      2m 17s Fill the tables ...                                                            .\n",
      "..............................................................................................\n",
      "|      2m 22s OK    book           name           : max size =      13 of    32\n",
      "|      2m 22s OK    clause_atom    text           : max size =     271 of   512\n",
      "|      2m 22s OK    lexicon        entry          : max size =      14 of    32\n",
      "|      2m 22s OK    lexicon        entry_heb      : max size =      15 of    32\n",
      "|      2m 22s OK    lexicon        entryid        : max size =      15 of    32\n",
      "|      2m 22s OK    lexicon        entryid_heb    : max size =      16 of    32\n",
      "|      2m 22s OK    lexicon        g_entry        : max size =      24 of    32\n",
      "|      2m 22s OK    lexicon        g_entry_heb    : max size =      23 of    32\n",
      "|      2m 22s OK    lexicon        gloss          : max size =      27 of    32\n",
      "|      2m 22s OK    lexicon        id             : max size =      16 of    32\n",
      "|      2m 22s OK    lexicon        lan            : max size =       3 of     4\n",
      "|      2m 22s OK    lexicon        nametype       : max size =      14 of    16\n",
      "|      2m 22s OK    lexicon        pos            : max size =       4 of     8\n",
      "|      2m 22s OK    lexicon        root           : max size =      11 of    32\n",
      "|      2m 22s OK    lexicon        subpos         : max size =       4 of     8\n",
      "|      2m 22s OK    verse          text           : max size =     449 of  1024\n",
      "|      2m 22s OK    verse          xml            : max size =    2869 of  4096\n",
      "|      2m 22s Done\n",
      "All lexemes have been found in the lexicon\n",
      "..............................................................................................\n",
      ".      2m 22s Generating word info data ...                                                  .\n",
      "..............................................................................................\n",
      "|      2m 22s \tGenesis\n",
      "|      2m 30s \tExodus\n",
      "|      2m 37s \tLeviticus\n",
      "|      2m 42s \tNumeri\n",
      "|      2m 49s \tDeuteronomium\n",
      "|      2m 54s \tJosua\n",
      "|      2m 59s \tJudices\n",
      "|      3m 03s \tSamuel_I\n",
      "|      3m 08s \tSamuel_II\n",
      "|      3m 13s \tReges_I\n",
      "|      3m 18s \tReges_II\n",
      "|      3m 23s \tJesaia\n",
      "|      3m 30s \tJeremia\n",
      "|      3m 38s \tEzechiel\n",
      "|      3m 46s \tHosea\n",
      "|      3m 47s \tJoel\n",
      "|      3m 47s \tAmos\n",
      "|      3m 48s \tObadia\n",
      "|      3m 48s \tJona\n",
      "|      3m 49s \tMicha\n",
      "|      3m 49s \tNahum\n",
      "|      3m 49s \tHabakuk\n",
      "|      3m 50s \tZephania\n",
      "|      3m 50s \tHaggai\n",
      "|      3m 50s \tSacharia\n",
      "|      3m 51s \tMaleachi\n",
      "|      3m 52s \tPsalmi\n",
      "|      4m 00s \tIob\n",
      "|      4m 03s \tProverbia\n",
      "|      4m 06s \tRuth\n",
      "|      4m 06s \tCanticum\n",
      "|      4m 07s \tEcclesiastes\n",
      "|      4m 08s \tThreni\n",
      "|      4m 08s \tEsther\n",
      "|      4m 10s \tDaniel\n",
      "|      4m 12s \tEsra\n",
      "|      4m 14s \tNehemia\n",
      "|      4m 16s \tChronica_I\n",
      "|      4m 20s \tChronica_II\n",
      "|      4m 26s Done\n",
      "OK    word           word_heb            : max size =      28 of    32\n",
      "OK    word           word_ktv            : max size =      15 of    32\n",
      "OK    word           word_vlex           : max size =      23 of    32\n",
      "OK    word           word_clex           : max size =      15 of    32\n",
      "OK    word           word_tran           : max size =      28 of    32\n",
      "OK    word           word_phono          : max size =      23 of    32\n",
      "OK    word           word_phono_sep      : max size =       3 of     8\n",
      "OK    word           word_lex            : max size =      15 of    32\n",
      "OK    word           word_glex           : max size =      24 of    32\n",
      "OK    word           word_gloss          : max size =      27 of    32\n",
      "OK    word           word_lang           : max size =       3 of     8\n",
      "OK    word           word_pos            : max size =       4 of     8\n",
      "OK    word           word_pdp            : max size =       4 of     8\n",
      "OK    word           word_subpos         : max size =       4 of     8\n",
      "OK    word           word_nmtp           : max size =      14 of    32\n",
      "OK    word           word_tense          : max size =       4 of     8\n",
      "OK    word           word_stem           : max size =       4 of     8\n",
      "OK    word           word_gender         : max size =       7 of     8\n",
      "OK    word           word_gnumber        : max size =       7 of     8\n",
      "OK    word           word_person         : max size =       7 of     8\n",
      "OK    word           word_state          : max size =       2 of     8\n",
      "OK    word           word_nme            : max size =       6 of     8\n",
      "OK    word           word_pfm            : max size =       6 of     8\n",
      "OK    word           word_prs            : max size =       6 of     8\n",
      "OK    word           word_uvf            : max size =       6 of     8\n",
      "OK    word           word_vbe            : max size =       3 of     8\n",
      "OK    word           word_vbs            : max size =       6 of     8\n",
      "OK    word           subphrase_border    : max size =       8 of    16\n",
      "OK    word           subphrase_number    : max size =      14 of    32\n",
      "OK    word           subphrase_rela      : max size =       3 of     8\n",
      "OK    word           phrase_border       : max size =       5 of     8\n",
      "OK    word           phrase_atom_rela    : max size =       4 of     8\n",
      "OK    word           phrase_function     : max size =       4 of     8\n",
      "OK    word           phrase_rela         : max size =       4 of     8\n",
      "OK    word           phrase_typ          : max size =       4 of     8\n",
      "OK    word           phrase_det          : max size =       3 of     8\n",
      "OK    word           clause_border       : max size =       5 of     8\n",
      "OK    word           clause_atom_pargr   : max size =      39 of    64\n",
      "OK    word           clause_rela         : max size =       4 of     8\n",
      "OK    word           clause_typ          : max size =       4 of     8\n",
      "OK    word           clause_txt          : max size =       7 of     8\n",
      "OK    word           sentence_border     : max size =       5 of     8\n",
      "..............................................................................................\n",
      ".      4m 26s Generating SQL ...                                                             .\n",
      "..............................................................................................\n",
      "|      4m 26s \ttable book\n",
      "|      4m 26s \ttable chapter\n",
      "|      4m 26s \ttable verse\n",
      "|      4m 26s \ttable clause_atom\n",
      "|      4m 26s \ttable lexicon\n",
      "|      4m 26s \ttable word\n",
      "|      4m 27s \ttable word_verse\n",
      "|      4m 27s Done\n",
      "|      4m 50s SUCCESS passageFromTf\n",
      "\n",
      "----------------------------------------------------------------------------------------------\n",
      "-      4m 50s SUCCES [pipeline/passageFromTf]                                                -\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "|      4m 50s \tDone\n"
     ]
    }
   ],
   "source": [
    "good = webPipeline(pipeline, versions=VERSIONS, force=True, kinds=KINDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##############################################################################################\n",
      "#                                                                                            #\n",
      "#      5m 07s Import MQL db for version 2021 locally                                         #\n",
      "#                                                                                            #\n",
      "##############################################################################################\n",
      "\n",
      "\n",
      "##############################################################################################\n",
      "#                                                                                            #\n",
      "#      5m 07s Drop database shebanq_etcbc2021                                                #\n",
      "#                                                                                            #\n",
      "##############################################################################################\n",
      "\n",
      "\n",
      "##############################################################################################\n",
      "#                                                                                            #\n",
      "#      5m 08s Importing MQL shebanq_etcbc2021 ...                                            #\n",
      "#                                                                                            #\n",
      "##############################################################################################\n",
      "\n",
      "|      7m 29s Dropping indices on word_objects...!\n",
      "\n",
      "|      7m 29s Creating indices on word_objects...!\n",
      "\n",
      "|      7m 29s Dropping indices on subphrase_objects...!\n",
      "\n",
      "|      7m 29s Creating indices on subphrase_objects...!\n",
      "\n",
      "|      7m 29s Dropping indices on phrase_atom_objects...!\n",
      "\n",
      "|      7m 29s Creating indices on phrase_atom_objects...!\n",
      "\n",
      "|      7m 29s Dropping indices on phrase_objects...!\n",
      "\n",
      "|      7m 29s Creating indices on phrase_objects...!\n",
      "\n",
      "|      7m 29s Dropping indices on clause_atom_objects...!\n",
      "\n",
      "|      7m 29s Creating indices on clause_atom_objects...!\n",
      "\n",
      "|      7m 29s Dropping indices on clause_objects...!\n",
      "\n",
      "|      7m 29s Creating indices on clause_objects...!\n",
      "\n",
      "|      7m 29s Dropping indices on sentence_atom_objects...!\n",
      "\n",
      "|      7m 29s Creating indices on sentence_atom_objects...!\n",
      "\n",
      "|      7m 29s Dropping indices on sentence_objects...!\n",
      "\n",
      "|      7m 29s Creating indices on sentence_objects...!\n",
      "\n",
      "|      7m 29s Dropping indices on half_verse_objects...!\n",
      "\n",
      "|      7m 29s Creating indices on half_verse_objects...!\n",
      "\n",
      "|      7m 29s Dropping indices on verse_objects...!\n",
      "\n",
      "|      7m 29s Creating indices on verse_objects...!\n",
      "\n",
      "|      7m 29s Dropping indices on lex_objects...!\n",
      "\n",
      "|      7m 29s Creating indices on lex_objects...!\n",
      "\n",
      "|      7m 29s Dropping indices on chapter_objects...!\n",
      "\n",
      "|      7m 29s Creating indices on chapter_objects...!\n",
      "\n",
      "|      7m 29s Dropping indices on book_objects...!\n",
      "\n",
      "|      7m 29s Creating indices on book_objects...!\n",
      "\n",
      "\n",
      "##############################################################################################\n",
      "#                                                                                            #\n",
      "#      7m 29s Imported MQL shebanq_etcbc2021                                                 #\n",
      "#                                                                                            #\n",
      "##############################################################################################\n",
      "\n",
      "\n",
      "##############################################################################################\n",
      "#                                                                                            #\n",
      "#      7m 29s Importing passage db for version 2021 ...                                      #\n",
      "#                                                                                            #\n",
      "##############################################################################################\n",
      "\n",
      "\n",
      "##############################################################################################\n",
      "#                                                                                            #\n",
      "#      7m 52s Imported passage db for version 2021                                           #\n",
      "#                                                                                            #\n",
      "##############################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# good = True\n",
    "if good:\n",
    "    good = importLocal(pipeline, versions=VERSIONS, kinds=KINDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##############################################################################################\n",
      "#                                                                                            #\n",
      "#      8m 10s Sending MQL database for version 2021 to server                                #\n",
      "#                                                                                            #\n",
      "##############################################################################################\n",
      "\n",
      "|      8m 10s \tshebanq_etcbc2021.mql.bz2\n",
      "|      8m 10s \tscp /Users/dirk/github/etcbc/bhsa/shebanq/2021/shebanq_etcbc2021.mql.bz2 dirkr@clarin11.dans.knaw.nl:/home/dirkr/shebanq-install/shebanq_etcbc2021.mql.bz2\n",
      "|      8m 35s \tdone\n",
      "\n",
      "##############################################################################################\n",
      "#                                                                                            #\n",
      "#      8m 35s Sending passage database for version 2021 to server                            #\n",
      "#                                                                                            #\n",
      "##############################################################################################\n",
      "\n",
      "|      8m 35s \tshebanq_passage2021.sql.gz\n",
      "|      8m 35s \tscp /Users/dirk/github/etcbc/bhsa/shebanq/2021/shebanq_passage2021.sql.gz dirkr@clarin11.dans.knaw.nl:/home/dirkr/shebanq-install/shebanq_passage2021.sql.gz\n",
      "|      9m 00s \tdone\n"
     ]
    }
   ],
   "source": [
    "# good = True\n",
    "if good:\n",
    "    good = copyServer(pipeline, user, server, remoteDir, versions=VERSIONS, kinds=KINDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
