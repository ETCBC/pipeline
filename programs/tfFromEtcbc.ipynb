{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "![pipeline](pictures/pictures.002.png)\n",
    "\n",
    "# Text-Fabric from ETCBC\n",
    "\n",
    "This notebook assembles the data from the ETCBC that is needed\n",
    "to compile its datasets in text-fabric-format on GitHub.\n",
    "Ultimately the data for the website [SHEBANQ](https://shebanq.ancient-data.org) will be\n",
    "derived from these Text-Fabric-sources.\n",
    "\n",
    "## Pipeline\n",
    "This is **pipe 1** of the pipeline from ETCBC data to the website SHEBANQ.\n",
    "\n",
    "A run of this pipe produces a data *version*.\n",
    "It should be run whenever there are new or updated data sources present that affect the output data.\n",
    "Since all input data is delivered in a GitHub repo, we have excellent machinery to\n",
    "work with versioning.\n",
    "\n",
    "The pipe works by executing a series of programs, contained in GitHub repositories.\n",
    "For each repository in the pipe, a series of notebooks will be executed.\n",
    "See [script mode](https://github.com/ETCBC/pipeline/blob/master/README.md#operation) for\n",
    "details on how we call notebooks.\n",
    "\n",
    "All this is specified in the configuration below.\n",
    "\n",
    "### Core data\n",
    "\n",
    "The core data is delivered by the ETCBC as `bhsa.mql.bz2` in\n",
    "the GitHub repo [bhsa](https://github.com/ETCBC/bhsa) in directory `source`.\n",
    "\n",
    "This data will be converted by `coreData` in the `programs` directory.\n",
    "\n",
    "The result of this action will be an updated Text-Fabric resource in its\n",
    "`tf/core` directory.\n",
    "\n",
    "### Additional data\n",
    "\n",
    "Researchers have contributed to the dataset,\n",
    "but not all that data is in the core.\n",
    "They are typically in the repository where the research has been\n",
    "executed, and where the data is documented.\n",
    "\n",
    "Before the pipe starts, these repos must be pulled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline import runPipeline, copyVersion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORE_NAME = \"bhsa\"\n",
    "\n",
    "if \"SCRIPT\" not in locals():\n",
    "    SCRIPT = False\n",
    "    DEFAULT_CORE_NAME = CORE_NAME\n",
    "    DEFAULT_VERSION = \"2021\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline settings\n",
    "\n",
    "Here all the nitty-gritty differences between versions are stated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = dict(\n",
    "    defaults=dict(\n",
    "        CORE_NAME=CORE_NAME,\n",
    "        VERSION=DEFAULT_VERSION,\n",
    "        LANG_FEATURE=\"languageISO\",\n",
    "        OCC_FEATURE=\"g_cons\",\n",
    "        LEX_FEATURE=\"lex\",\n",
    "        TEXT_FEATURE=\"g_word_utf8\",\n",
    "        TRAILER_FEATURE=\"trailer_utf8\",\n",
    "        DO_VOCALIZED_LEXEME=True,\n",
    "        EXTRA_OVERLAP=\"\",\n",
    "        LEX_FORMATS=\"@fmt:lex-trans-plain={lex0} \",\n",
    "        RENAME=(\n",
    "            (\"g_suffix\", \"trailer\"),\n",
    "            (\"g_suffix_utf8\", \"trailer_utf8\"),\n",
    "        ),\n",
    "    ),\n",
    "    versions={\n",
    "        \"_temp\": dict(\n",
    "            LEX_FORMATS=\"@fmt:lex-default={voc_lex_utf8} \",\n",
    "        ),\n",
    "        \"c\": dict(\n",
    "            LEX_FORMATS=\"@fmt:lex-default={voc_lex_utf8} \",\n",
    "        ),\n",
    "        \"2021\": dict(\n",
    "            LEX_FORMATS=\"@fmt:lex-default={voc_lex_utf8} \",\n",
    "        ),\n",
    "        \"2017\": dict(\n",
    "            LEX_FORMATS=\"@fmt:lex-default={voc_lex_utf8} \",\n",
    "        ),\n",
    "        \"2016\": dict(\n",
    "            LEX_FORMATS=\"@fmt:lex-default={voc_lex_utf8} \",\n",
    "        ),\n",
    "        \"4b\": dict(\n",
    "            LANG_FEATURE=\"language\",\n",
    "            DO_VOCALIZED_LEXEME=False,\n",
    "            EXTRA_OVERLAP=\"gloss nametype\",\n",
    "            LEX_FORMATS=\"@fmt:lex-trans-plain={lex} \",\n",
    "        ),\n",
    "        \"4\": dict(\n",
    "            LANG_FEATURE=\"language\",\n",
    "            DO_VOCALIZED_LEXEME=False,\n",
    "            EXTRA_OVERLAP=\"gloss nametype\",\n",
    "            LEX_FORMATS=\"@fmt:lex-trans-plain={lex} \",\n",
    "        ),\n",
    "        \"3\": dict(\n",
    "            LANG_FEATURE=\"language\",\n",
    "            OCC_FEATURE=\"surface_consonants\",\n",
    "            LEX_FEATURE=\"lexeme\",\n",
    "            TEXT_FEATURE=\"text\",\n",
    "            TRAILER_FEATURE=\"suffix\",\n",
    "            LEX_FORMATS=\"@fmt:lex-trans-plain={lexeme} \",\n",
    "        ),\n",
    "    },\n",
    "    repoOrder=\"\"\"\n",
    "        bhsa\n",
    "        phono\n",
    "        valence\n",
    "        parallels\n",
    "        bridging\n",
    "        trees\n",
    "    \"\"\",\n",
    "    repoConfig=dict(\n",
    "        bhsa=(\n",
    "            dict(\n",
    "                task=\"coreData\",\n",
    "            ),\n",
    "            dict(\n",
    "                task=\"bookNames\",\n",
    "                omit={},\n",
    "            ),\n",
    "            dict(\n",
    "                task=\"lexicon\",\n",
    "                omit={\"3\"},\n",
    "            ),\n",
    "            dict(\n",
    "                task=\"paragraphs\",\n",
    "                omit={\"3\", \"4\", \"4b\"},\n",
    "            ),\n",
    "            dict(\n",
    "                task=\"ketivQere\",\n",
    "                omit={\"3\", \"4\", \"4b\"},\n",
    "            ),\n",
    "            dict(\n",
    "                task=\"stats\",\n",
    "                omit={\"4\", \"4b\"},\n",
    "            ),\n",
    "        ),\n",
    "        phono=(\n",
    "            dict(\n",
    "                task=\"phono\",\n",
    "                omit={\"3\", \"4\", \"4b\"},\n",
    "            ),\n",
    "        ),\n",
    "        valence=(\n",
    "            dict(\n",
    "                task=\"enrich\",\n",
    "                omit={\"3\"},\n",
    "            ),\n",
    "            dict(\n",
    "                task=\"flowchart\",\n",
    "                omit={\"3\"},\n",
    "            ),\n",
    "        ),\n",
    "        parallels=(\n",
    "            dict(\n",
    "                task=\"parallels\",\n",
    "                omit={},\n",
    "                params=dict(\n",
    "                    FORCE_MATRIX=False,\n",
    "                ),\n",
    "            ),\n",
    "        ),\n",
    "        trees=(\n",
    "            dict(\n",
    "                task=\"trees\",\n",
    "            ),\n",
    "        ),\n",
    "        bridging=(\n",
    "            dict(\n",
    "                task=\"BHSAbridgeOSM\",\n",
    "                omit={\"3\", \"4\", \"4b\"},\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    repoDataDirs=dict(\n",
    "        bhsa=\"source _temp tf shebanq\",\n",
    "        phono=\"_temp tf\",\n",
    "        valence=\"source _temp tf shebanq\",\n",
    "        parallels=\"source _temp tf\",\n",
    "        trees=\"source _temp tf\",\n",
    "        bridging=\"source _temp tf\",\n",
    "    ),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Run the pipeline\n",
    "\n",
    "To run everything from scratch:\n",
    "\n",
    "```python\n",
    "good = runPipeline(pipeline, versions=['3', '4', '4b', '2016', '2017', '2021', 'c'], force=True)\n",
    "```\n",
    "\n",
    "To run the SHEBANQ versions from scratch:\n",
    "\n",
    "```python\n",
    "good = runPipeline(pipeline, versions=['4', '4b', '2017', '2021'], force=True)\n",
    "```\n",
    "\n",
    "To make a new version called `temp`\n",
    "\n",
    "```python\n",
    "good = runPipeline(pipeline, versions=['_temp'], force=True) # a new candidate for 'c'\n",
    "```\n",
    "\n",
    "To copy the `_temp` version over to the continuous version `c`:\n",
    "\n",
    "```python\n",
    "if good:\n",
    "    copyVersion(pipeline, '_temp', 'c')\n",
    "```\n",
    "This will copy all data, `source`, `_temp` and `tf` over from `_temp` to `c`.\n",
    "\n",
    "If you want to create the node mappings between versions,\n",
    "go to the `versionMappings` notebook in the BHSA repo and run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##############################################################################################\n",
      "#                                                                                            #\n",
      "#     22m 26s Make version [2021]                                                            #\n",
      "#                                                                                            #\n",
      "##############################################################################################\n",
      "\n",
      "\n",
      "##############################################################################################\n",
      "#                                                                                            #\n",
      "#     22m 26s Skipping bhsa because it is not in the repos parameter                         #\n",
      "#                                                                                            #\n",
      "##############################################################################################\n",
      "\n",
      "\n",
      "##############################################################################################\n",
      "#                                                                                            #\n",
      "#     22m 26s Skipping phono because it is not in the repos parameter                        #\n",
      "#                                                                                            #\n",
      "##############################################################################################\n",
      "\n",
      "\n",
      "**********************************************************************************************\n",
      "*                                                                                            *\n",
      "*     22m 26s Make repo [valence]                                                            *\n",
      "*                                                                                            *\n",
      "**********************************************************************************************\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------\n",
      "-     22m 26s Run notebook [valence/enrich] with parameters:                                 -\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "|     22m 26s \tCORE_NAME            = bhsa\n",
      "|     22m 26s \tDO_VOCALIZED_LEXEME  = True\n",
      "|     22m 26s \tEXTRA_OVERLAP        = \n",
      "|     22m 26s \tLANG_FEATURE         = languageISO\n",
      "|     22m 26s \tLEX_FEATURE          = lex\n",
      "|     22m 26s \tLEX_FORMATS          = @fmt:lex-default={voc_lex_utf8} \n",
      "|     22m 26s \tOCC_FEATURE          = g_cons\n",
      "|     22m 26s \tRENAME               = (('g_suffix', 'trailer'), ('g_suffix_utf8', 'trailer_utf8'))\n",
      "|     22m 26s \tTEXT_FEATURE         = g_word_utf8\n",
      "|     22m 26s \tTRAILER_FEATURE      = trailer_utf8\n",
      "|     22m 26s \tVERSION              = 2021\n",
      "|     22m 28s \tDestination /Users/werk/github/etcbc/valence/tf/2021/.tf/valence.tfx does not exist\n",
      "True True\n",
      "..............................................................................................\n",
      ".     22m 28s Load the existing TF dataset                                                   .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 9.1.7\n",
      "Api reference : https://annotation.github.io/text-fabric/tf/cheatsheet.html\n",
      "\n",
      "114 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s Dataset without structure sections in otext:no structure functions in the T-API\n",
      "    22s All features loaded/computed - for details use TF.isLoaded()\n",
      "..............................................................................................\n",
      ".     22m 50s Finding occurrences ...                                                        .\n",
      "..............................................................................................\n",
      "|     22m 51s \tDone\n",
      "|     22m 51s \tAll:      1380 verbs with  73710 verb occurrences in 70150 clauses\n",
      "|     22m 51s \tSelected:   18 verbs with  16209 verb occurrences in 16052 clauses\n",
      "|     22m 51s \t<BR   556 occurrences of which   33 outside a predicate phrase\n",
      "|     22m 51s \t<FH  2629 occurrences of which   59 outside a predicate phrase\n",
      "|     22m 51s \t<LH   890 occurrences of which   10 outside a predicate phrase\n",
      "|     22m 51s \tBR>    54 occurrences of which    3 outside a predicate phrase\n",
      "|     22m 51s \tBW>  2570 occurrences of which   27 outside a predicate phrase\n",
      "|     22m 51s \tCJT    85 occurrences of which    1 outside a predicate phrase\n",
      "|     22m 51s \tCWB  1056 occurrences of which   22 outside a predicate phrase\n",
      "|     22m 51s \tFJM   609 occurrences of which    3 outside a predicate phrase\n",
      "|     22m 51s \tHLK  1554 occurrences of which   32 outside a predicate phrase\n",
      "|     22m 51s \tJRD   377 occurrences of which   16 outside a predicate phrase\n",
      "|     22m 51s \tJY>  1069 occurrences of which   32 outside a predicate phrase\n",
      "|     22m 51s \tNF>   656 occurrences of which   53 outside a predicate phrase\n",
      "|     22m 51s \tNPL   445 occurrences of which   11 outside a predicate phrase\n",
      "|     22m 51s \tNTN  2017 occurrences of which   10 outside a predicate phrase\n",
      "|     22m 51s \tNWS   159 occurrences of which    4 outside a predicate phrase\n",
      "|     22m 51s \tPQD   303 occurrences of which   72 outside a predicate phrase\n",
      "|     22m 51s \tQR>   883 occurrences of which   12 outside a predicate phrase\n",
      "|     22m 51s \tSWR   297 occurrences of which    1 outside a predicate phrase\n",
      "..............................................................................................\n",
      ".     22m 51s Generating blank correction sheets ...                                         .\n",
      "..............................................................................................\n",
      "|     22m 51s \tas /Users/werk/github/etcbc/valence/source/2021/corr_blank/{verb}.csv\n",
      "|     22m 51s \t\tfor verb NTN\n",
      "|     22m 51s \t\tfor verb NWS\n",
      "|     22m 51s \t\tfor verb oLH\n",
      "|     22m 51s \t\tfor verb BRa\n",
      "|     22m 51s \t\tfor verb oBR\n",
      "|     22m 51s \t\tfor verb JYa\n",
      "|     22m 51s \t\tfor verb HLK\n",
      "|     22m 51s \t\tfor verb QRa\n",
      "|     22m 52s \t\tfor verb oFH\n",
      "|     22m 52s \t\tfor verb FJM\n",
      "|     22m 52s \t\tfor verb JRD\n",
      "|     22m 52s \t\tfor verb NFa\n",
      "|     22m 52s \t\tfor verb CWB\n",
      "|     22m 52s \t\tfor verb PQD\n",
      "|     22m 52s \t\tfor verb NPL\n",
      "|     22m 52s \t\tfor verb CJT\n",
      "|     22m 52s \t\tfor verb BWa\n",
      "|     22m 52s \t\tfor verb SWR\n",
      "|     22m 52s \t52060  phrases seen 1  time(s)\n",
      "|     22m 52s \t185    phrases seen 2  time(s)\n",
      "|     22m 52s \t9      phrases seen 3  time(s)\n",
      "|     22m 52s \tTotal phrases seen: 52254\n",
      "..............................................................................................\n",
      ".     22m 52s Processing filled correction sheets ...                                        .\n",
      "..............................................................................................\n",
      "|     22m 52s \tas /Users/werk/github/etcbc/valence/source/2021/corr_filled/{verb}.csv\n",
      "|     22m 52s \t\tNO file for oBR\n",
      "|     22m 52s \t\tNO file for oFH\n",
      "|     22m 52s \t\tNO file for oLH\n",
      "|     22m 52s \t\tNO file for BRa\n",
      "|     22m 52s \t\tNO file for BWa\n",
      "|     22m 52s \t\tNO file for CJT\n",
      "|     22m 52s \t\tNO file for CWB\n",
      "|     22m 52s \t\tNO file for FJM\n",
      "|     22m 52s \t\tNO file for HLK\n",
      "|     22m 52s \t\tNO file for JRD\n",
      "|     22m 52s \t\tNO file for JYa\n",
      "|     22m 52s \t\tNO file for NFa\n",
      "|     22m 52s \t\tNO file for NPL\n",
      "|     22m 52s \t\tNO file for NTN\n",
      "|     22m 52s \t\tNO file for NWS\n",
      "|     22m 52s \t\tNO file for PQD\n",
      "|     22m 52s \t\tNO file for QRa\n",
      "|     22m 52s \t\tNO file for SWR\n",
      "|     22m 52s \tFound 0 corrections in the phrase function\n",
      "|     22m 52s \tTotal phrases seen: 0\n",
      "..............................................................................................\n",
      ".     22m 52s 6 Enrich field specifications OK                                               .\n",
      "..............................................................................................\n",
      "|     22m 52s \tgrammatical has possible values\n",
      "|     22m 52s \t\tprincipal_direct_object\n",
      "|     22m 52s \t\t*\n",
      "|     22m 52s \t\tdirect_object\n",
      "|     22m 52s \t\tL_object\n",
      "|     22m 52s \t\tindirect_object\n",
      "|     22m 52s \t\tinfinitive_object\n",
      "|     22m 52s \t\tNA\n",
      "|     22m 52s \t\tK_object\n",
      "|     22m 52s \t\tsubject\n",
      "|     22m 52s \t\tNP_direct_object\n",
      "|     22m 52s \tlexical has possible values\n",
      "|     22m 52s \t\ttime\n",
      "|     22m 52s \t\tlocation\n",
      "|     22m 52s \toriginal has possible values\n",
      "|     22m 52s \t\tprincipal_direct_object\n",
      "|     22m 52s \t\t*\n",
      "|     22m 52s \t\tdirect_object\n",
      "|     22m 52s \t\tL_object\n",
      "|     22m 52s \t\tindirect_object\n",
      "|     22m 52s \t\tinfinitive_object\n",
      "|     22m 52s \t\tNA\n",
      "|     22m 52s \t\tK_object\n",
      "|     22m 52s \t\tsubject\n",
      "|     22m 52s \t\tNP_direct_object\n",
      "|     22m 52s \tpredication has possible values\n",
      "|     22m 52s \t\tNA\n",
      "|     22m 52s \t\tregular\n",
      "|     22m 52s \t\tcopula\n",
      "|     22m 52s \tsemantic has possible values\n",
      "|     22m 52s \t\tlocation\n",
      "|     22m 52s \t\ttime\n",
      "|     22m 52s \t\tinstrument\n",
      "|     22m 52s \t\tbenefactive\n",
      "|     22m 52s \t\tmanner\n",
      "|     22m 52s \tvalence has possible values\n",
      "|     22m 52s \t\tcomplement\n",
      "|     22m 52s \t\tadjunct\n",
      "|     22m 52s \t\tcore\n",
      "..............................................................................................\n",
      ".     22m 52s \tChecking enrich baseline rules                                                .\n",
      "..............................................................................................\n",
      "|     22m 52s \tEnrich baseline rules are OK (204 good)\n",
      "..............................................................................................\n",
      ".     22m 52s Finding direct objects and determining the principal one                       .\n",
      "..............................................................................................\n",
      "|     22m 54s \tDone\n",
      "|     22m 54s \t 3649 clauses with  1  principal object\n",
      "|     22m 54s \t66501 clauses with  0  principal objects\n",
      "|     22m 54s \t 3649 clauses with  a  principal object\n",
      "|     22m 54s \t23694 clauses with  1     direct object\n",
      "|     22m 54s \t46456 clauses with  0     direct objects\n",
      "|     22m 54s \t23694 clauses with  a     direct object\n",
      "|     22m 54s \t 1001 clauses with  1         NP object\n",
      "|     22m 54s \t69149 clauses with  0         NP objects\n",
      "|     22m 54s \t 1001 clauses with  a         NP object\n",
      "|     22m 54s \t   33 clauses with  2          L objects\n",
      "|     22m 54s \t 3827 clauses with  1          L object\n",
      "|     22m 54s \t66290 clauses with  0          L objects\n",
      "|     22m 54s \t 3860 clauses with  a          L object\n",
      "|     22m 54s \t  115 clauses with  1          K object\n",
      "|     22m 54s \t70035 clauses with  0          K objects\n",
      "|     22m 54s \t  115 clauses with  a          K object\n",
      "|     22m 54s \t 1310 clauses with  1     clause object\n",
      "|     22m 54s \t68840 clauses with  0     clause objects\n",
      "|     22m 54s \t 1310 clauses with  a     clause object\n",
      "|     22m 54s \t    1 clauses with  3 infinitive objects\n",
      "|     22m 54s \t   18 clauses with  2 infinitive objects\n",
      "|     22m 54s \t 1196 clauses with  1 infinitive object\n",
      "|     22m 54s \t68935 clauses with  0 infinitive objects\n",
      "|     22m 54s \t 1215 clauses with  a infinitive object\n",
      "..............................................................................................\n",
      ".     22m 54s Determinig kind of complements                                                 .\n",
      "..............................................................................................\n",
      "|     22m 55s \tDone\n",
      "|     22m 55s \tPhrases of kind C :  16805\n",
      "|     22m 55s \tPhrases of kind L :  12367\n",
      "|     22m 55s \tPhrases of kind I :   7839\n",
      "|     22m 55s \tTotal complements :  37011\n",
      "|     22m 55s \tTotal phrases     : 214525\n",
      "..............................................................................................\n",
      ".     22m 55s Checking enrichment logic                                                      .\n",
      "..............................................................................................\n",
      "|     22m 55s \tAll 6 rules OK\n",
      "..............................................................................................\n",
      ".     22m 55s Generating enrichments                                                         .\n",
      "..............................................................................................\n",
      "|     22m 58s \tGenerated enrichment values for 1380 verbs:\n",
      "|     22m 58s \tEnriched values for 221353 nodes\n",
      "|     22m 58s \tOverview of rule applications:\n",
      "|     22m 58s generic-phrase rules:\n",
      "|     22m 58s  28259 generic-phrase rule applications\n",
      "|     22m 58s generic-clause rules:\n",
      "|     22m 58s   2635 generic-clause rule applications\n",
      "|     22m 58s  30894 generic rule applications\n",
      "|     22m 58s specific-phrase rules:\n",
      "|     22m 58s    117 specific-phrase rule applications\n",
      "|     22m 58s    117 specific rule applications\n",
      "|     22m 58s \t214525 phrase seen in total\n",
      "|     22m 58s \t  6828 clause seen in total\n",
      "..............................................................................................\n",
      ".     22m 58s Generate blank enrichment sheets                                               .\n",
      "..............................................................................................\n",
      "|     22m 58s \tas /Users/werk/github/etcbc/valence/source/2021/enrich_blank/{verb}.csv\n",
      "|     22m 59s \t\tfor verb NTN ( 9822 rows)\n",
      "|     22m 59s \t\tfor verb NWS (  618 rows)\n",
      "|     22m 59s \t\tfor verb <LH ( 3893 rows)\n",
      "|     22m 59s \t\tfor verb BR> (  219 rows)\n",
      "|     22m 59s \t\tfor verb <BR ( 2349 rows)\n",
      "|     22m 59s \t\tfor verb JY> ( 4623 rows)\n",
      "|     22m 59s \t\tfor verb HLK ( 5814 rows)\n",
      "|     22m 59s \t\tfor verb QR> ( 3726 rows)\n",
      "|     23m 00s \t\tfor verb <FH (11315 rows)\n",
      "|     23m 00s \t\tfor verb FJM ( 2918 rows)\n",
      "|     23m 00s \t\tfor verb JRD ( 1593 rows)\n",
      "|     23m 00s \t\tfor verb NF> ( 2886 rows)\n",
      "|     23m 00s \t\tfor verb CWB ( 4325 rows)\n",
      "|     23m 00s \t\tfor verb PQD ( 1283 rows)\n",
      "|     23m 00s \t\tfor verb NPL ( 1933 rows)\n",
      "|     23m 00s \t\tfor verb CJT (  381 rows)\n",
      "|     23m 00s \t\tfor verb BW> (11087 rows)\n",
      "|     23m 00s \t\tfor verb SWR ( 1272 rows)\n",
      "|     23m 00s \tDone\n",
      "..............................................................................................\n",
      ".     23m 00s Processing enrichment sheets ...                                               .\n",
      "..............................................................................................\n",
      "|     23m 00s \tas /Users/werk/github/etcbc/valence/source/2021/enrich_filled/{verb}.csv\n",
      "|     23m 00s \tblank enrichment sheet for oBR\n",
      "|     23m 00s \tblank enrichment sheet for oFH\n",
      "|     23m 00s \tblank enrichment sheet for oLH\n",
      "|     23m 00s \tblank enrichment sheet for BRa\n",
      "|     23m 00s \tblank enrichment sheet for BWa\n",
      "|     23m 01s \tblank enrichment sheet for CJT\n",
      "|     23m 01s \tblank enrichment sheet for CWB\n",
      "|     23m 01s \tblank enrichment sheet for FJM\n",
      "|     23m 01s \tblank enrichment sheet for HLK\n",
      "|     23m 01s \tblank enrichment sheet for JRD\n",
      "|     23m 01s \tblank enrichment sheet for JYa\n",
      "|     23m 01s \tblank enrichment sheet for NFa\n",
      "|     23m 01s \tblank enrichment sheet for NPL\n",
      "|     23m 01s \tblank enrichment sheet for NTN\n",
      "|     23m 01s \tblank enrichment sheet for NWS\n",
      "|     23m 01s \tblank enrichment sheet for PQD\n",
      "|     23m 01s \tblank enrichment sheet for QRa\n",
      "|     23m 01s \tblank enrichment sheet for SWR\n",
      "|     23m 01s \tOK: The used blank enrichment sheets have legal values\n",
      "|     23m 01s \tOK: The used blank enrichment sheets are consistent\n",
      "|     23m 01s \tOK: The used filled enrichment sheets have legal values\n",
      "|     23m 01s \tOK: The used filled enrichment sheets are consistent\n",
      "|     23m 01s \tOK: all enriched nodes where phrase nodes\n",
      "|     23m 01s \tOK: all enriched nodes occurred in the blank sheet\n",
      "|     23m 01s \tthere are no manual correction/enrichment annotations\n",
      "..............................................................................................\n",
      ".     23m 01s Combine the manual results with the generic results                            .\n",
      "..............................................................................................\n",
      "|     23m 01s \tAnnotations from sheets for 53743 nodes\n",
      "|     23m 01s \tMerging 221353 annotations from generic enrichment\n",
      "|     23m 01s \tResulting in annotations for 221353 nodes\n",
      "..............................................................................................\n",
      ".     23m 02s Writing TF enrichment features                                                 .\n",
      "..............................................................................................\n",
      "..............................................................................................\n",
      ".     23m 04s Check differences with previous version                                        .\n",
      "..............................................................................................\n",
      "|     23m 04s \tno features to add\n",
      "|     23m 04s \tno features to delete\n",
      "|     23m 04s \t9 features in common\n",
      "|     23m 04s cfunction                 ... no changes\n",
      "|     23m 04s f_correction              ... no changes\n",
      "|     23m 04s grammatical               ... no changes\n",
      "|     23m 04s lexical                   ... no changes\n",
      "|     23m 04s original                  ... no changes\n",
      "|     23m 04s predication               ... no changes\n",
      "|     23m 04s s_manual                  ... no changes\n",
      "|     23m 04s semantic                  ... no changes\n",
      "|     23m 04s valence                   ... no changes\n",
      "|     23m 05s Done\n",
      "..............................................................................................\n",
      ".     23m 05s Deliver features to /Users/werk/github/etcbc/valence/tf/2021                   .\n",
      "..............................................................................................\n",
      "|     23m 05s \tvalence\n",
      "|     23m 05s \tpredication\n",
      "|     23m 05s \tgrammatical\n",
      "|     23m 05s \toriginal\n",
      "|     23m 05s \tlexical\n",
      "|     23m 05s \tsemantic\n",
      "|     23m 05s \tf_correction\n",
      "|     23m 05s \ts_manual\n",
      "|     23m 05s \tcfunction\n",
      "..............................................................................................\n",
      ".     23m 05s Load and compile the new TF features                                           .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 9.1.7\n",
      "Api reference : https://annotation.github.io/text-fabric/tf/cheatsheet.html\n",
      "\n",
      "124 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s Dataset without structure sections in otext:no structure functions in the T-API\n",
      "   |     0.28s T cfunction            from ~/github/etcbc/valence/tf/2021\n",
      "   |     0.22s T f_correction         from ~/github/etcbc/valence/tf/2021\n",
      "   |     0.39s T grammatical          from ~/github/etcbc/valence/tf/2021\n",
      "   |     0.31s T lexical              from ~/github/etcbc/valence/tf/2021\n",
      "   |     0.25s T original             from ~/github/etcbc/valence/tf/2021\n",
      "   |     0.41s T predication          from ~/github/etcbc/valence/tf/2021\n",
      "   |     0.24s T s_manual             from ~/github/etcbc/valence/tf/2021\n",
      "   |     0.28s T semantic             from ~/github/etcbc/valence/tf/2021\n",
      "   |     0.39s T valence              from ~/github/etcbc/valence/tf/2021\n",
      "    23s All features loaded/computed - for details use TF.isLoaded()\n",
      "Time - Time - True\n",
      "Pred - Pred - True\n",
      "Subj - Subj - True\n",
      "Objc - Objc - True\n",
      "Conj -  - True\n",
      "Subj -  - True\n",
      "Pred -  - True\n",
      "PreC -  - True\n",
      "Conj - None - False\n",
      "Subj - None - False\n",
      "|     23m 28s SUCCESS enrich\n",
      "\n",
      "----------------------------------------------------------------------------------------------\n",
      "-     23m 28s SUCCES [valence/enrich]                                                        -\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------\n",
      "-     23m 28s Run notebook [valence/flowchart] with parameters:                              -\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "|     23m 28s \tCORE_NAME            = bhsa\n",
      "|     23m 28s \tDO_VOCALIZED_LEXEME  = True\n",
      "|     23m 28s \tEXTRA_OVERLAP        = \n",
      "|     23m 28s \tLANG_FEATURE         = languageISO\n",
      "|     23m 28s \tLEX_FEATURE          = lex\n",
      "|     23m 28s \tLEX_FORMATS          = @fmt:lex-default={voc_lex_utf8} \n",
      "|     23m 28s \tOCC_FEATURE          = g_cons\n",
      "|     23m 28s \tRENAME               = (('g_suffix', 'trailer'), ('g_suffix_utf8', 'trailer_utf8'))\n",
      "|     23m 28s \tTEXT_FEATURE         = g_word_utf8\n",
      "|     23m 28s \tTRAILER_FEATURE      = trailer_utf8\n",
      "|     23m 28s \tVERSION              = 2021\n",
      "|     23m 29s \tDestination /Users/werk/github/etcbc/valence/tf/2021/.tf/sense.tfx does not exist\n",
      "..............................................................................................\n",
      ".     23m 29s Load the existing TF dataset                                                   .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 9.1.7\n",
      "Api reference : https://annotation.github.io/text-fabric/tf/cheatsheet.html\n",
      "\n",
      "124 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s Dataset without structure sections in otext:no structure functions in the T-API\n",
      "    23s All features loaded/computed - for details use TF.isLoaded()\n",
      "..............................................................................................\n",
      ".     23m 52s Making the verb-clause index                                                   .\n",
      "..............................................................................................\n",
      "|     23m 53s \tDone (69439 clauses)\n",
      "..............................................................................................\n",
      ".     23m 53s Finding key constituents                                                       .\n",
      "..............................................................................................\n",
      "|     23m 55s \tDone, 47619 clauses with relevant constituents\n",
      "..............................................................................................\n",
      ".     23m 55s Counting constituents                                                          .\n",
      "..............................................................................................\n",
      "|     23m 55s \t22364 clauses with  1 dos        constituents\n",
      "|     23m 55s \t25255 clauses with  0 dos        constituents\n",
      "|     23m 55s \t22364 clauses with  a dos        constituent\n",
      "|     23m 55s \t 3556 clauses with  1 pdos       constituents\n",
      "|     23m 55s \t44063 clauses with  0 pdos       constituents\n",
      "|     23m 55s \t 3556 clauses with  a pdos       constituent\n",
      "|     23m 55s \t  989 clauses with  1 ndos       constituents\n",
      "|     23m 55s \t46630 clauses with  0 ndos       constituents\n",
      "|     23m 55s \t  989 clauses with  a ndos       constituent\n",
      "|     23m 55s \t  111 clauses with  1 kdos       constituents\n",
      "|     23m 55s \t47508 clauses with  0 kdos       constituents\n",
      "|     23m 55s \t  111 clauses with  a kdos       constituent\n",
      "|     23m 55s \t   33 clauses with  2 ldos       constituents\n",
      "|     23m 55s \t 3786 clauses with  1 ldos       constituents\n",
      "|     23m 55s \t43800 clauses with  0 ldos       constituents\n",
      "|     23m 55s \t 3819 clauses with  a ldos       constituent\n",
      "|     23m 55s \t    1 clauses with  3 idos       constituents\n",
      "|     23m 55s \t   18 clauses with  2 idos       constituents\n",
      "|     23m 55s \t 1193 clauses with  1 idos       constituents\n",
      "|     23m 55s \t46407 clauses with  0 idos       constituents\n",
      "|     23m 55s \t 1212 clauses with  a idos       constituent\n",
      "|     23m 55s \t 1310 clauses with  1 cdos       constituents\n",
      "|     23m 55s \t46309 clauses with  0 cdos       constituents\n",
      "|     23m 55s \t 1310 clauses with  a cdos       constituent\n",
      "|     23m 55s \t   58 clauses with  2 inds       constituents\n",
      "|     23m 55s \t 6254 clauses with  1 inds       constituents\n",
      "|     23m 55s \t41307 clauses with  0 inds       constituents\n",
      "|     23m 55s \t 6312 clauses with  a inds       constituent\n",
      "|     23m 55s \t    1 clauses with  6 locs       constituents\n",
      "|     23m 55s \t    1 clauses with  4 locs       constituents\n",
      "|     23m 55s \t   19 clauses with  3 locs       constituents\n",
      "|     23m 55s \t  380 clauses with  2 locs       constituents\n",
      "|     23m 55s \t12660 clauses with  1 locs       constituents\n",
      "|     23m 55s \t34558 clauses with  0 locs       constituents\n",
      "|     23m 55s \t13061 clauses with  a locs       constituent\n",
      "|     23m 55s \t    1 clauses with  3 cpls       constituents\n",
      "|     23m 55s \t   40 clauses with  2 cpls       constituents\n",
      "|     23m 55s \t 7226 clauses with  1 cpls       constituents\n",
      "|     23m 55s \t40352 clauses with  0 cpls       constituents\n",
      "|     23m 55s \t 7267 clauses with  a cpls       constituent\n",
      "|     23m 55s \t    2 clauses with  2 bens       constituents\n",
      "|     23m 55s \t  171 clauses with  1 bens       constituents\n",
      "|     23m 55s \t47446 clauses with  0 bens       constituents\n",
      "|     23m 55s \t  173 clauses with  a bens       constituent\n",
      "|     23m 55s \t69439 clauses\n",
      "..............................................................................................\n",
      ".     23m 55s Checking the flowcharts                                                        .\n",
      "..............................................................................................\n",
      "|     23m 55s \tNo flowchart for 1544 verbs, e.g. <BC, <BD, <BH, <BR, <BR=, <BT, <BV, <BV=, <CC, <CN\n",
      "|     23m 55s \tAll flowcharts belong to a verb in the corpus\n",
      "..............................................................................................\n",
      ".     23m 55s Applying the flowcharts                                                        .\n",
      "..............................................................................................\n",
      "|     23m 56s \t10000 clauses\n",
      "|     23m 58s \t20000 clauses\n",
      "|     23m 59s \t30000 clauses\n",
      "|     24m 01s \t40000 clauses\n",
      "|     24m 02s \t47381 clauses\n",
      "..............................................................................................\n",
      ".     24m 02s Writing sense feature to TF                                                    .\n",
      "..............................................................................................\n",
      "..............................................................................................\n",
      ".     24m 02s Check differences with previous version                                        .\n",
      "..............................................................................................\n",
      "|     24m 02s \tno features to add\n",
      "|     24m 02s \tno features to delete\n",
      "|     24m 02s \t1 features in common\n",
      "|     24m 02s sense                     ... no changes\n",
      "|     24m 02s Done\n",
      "..............................................................................................\n",
      ".     24m 02s Deliver features to /Users/werk/github/etcbc/valence/tf/2021                   .\n",
      "..............................................................................................\n",
      "|     24m 02s \tsense\n",
      "..............................................................................................\n",
      ".     24m 02s Load and compile the new TF features                                           .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 9.1.7\n",
      "Api reference : https://annotation.github.io/text-fabric/tf/cheatsheet.html\n",
      "\n",
      "124 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s Dataset without structure sections in otext:no structure functions in the T-API\n",
      "   |     0.11s T sense                from ~/github/etcbc/valence/tf/2021\n",
      "    20s All features loaded/computed - for details use TF.isLoaded()\n",
      "..............................................................................................\n",
      ".     24m 22s Show sense counts                                                              .\n",
      "..............................................................................................\n",
      "|     24m 22s \tSense labels = -- -b -c -i -p c. d- db dc di dp i. k. l. n.\n",
      "|     24m 22s \tCounted 47381 senses\n",
      "|     24m 22s \tAll relevant verbs have been assigned a sense\n",
      "|     24m 22s \t\t-- occurs  17941x\n",
      "|     24m 22s \t\td- occurs   9975x\n",
      "|     24m 22s \t\t-p occurs   6537x\n",
      "|     24m 22s \t\t-i occurs   3604x\n",
      "|     24m 22s \t\t-c occurs   3231x\n",
      "|     24m 22s \t\tdp occurs   1899x\n",
      "|     24m 22s \t\tdc occurs   1002x\n",
      "|     24m 22s \t\tdi occurs    918x\n",
      "|     24m 22s \t\tl. occurs    876x\n",
      "|     24m 22s \t\ti. occurs    630x\n",
      "|     24m 22s \t\tn. occurs    532x\n",
      "|     24m 22s \t\t-b occurs     64x\n",
      "|     24m 22s \t\tdb occurs     61x\n",
      "|     24m 22s \t\tc. occurs     57x\n",
      "|     24m 22s \t\tk. occurs     54x\n",
      "|     24m 22s SUCCESS flowchart\n",
      "\n",
      "----------------------------------------------------------------------------------------------\n",
      "-     24m 22s SUCCES [valence/flowchart]                                                     -\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "**********************************************************************************************\n",
      "*                                                                                            *\n",
      "*     24m 22s SUCCES [valence]                                                               *\n",
      "*                                                                                            *\n",
      "**********************************************************************************************\n",
      "\n",
      "\n",
      "**********************************************************************************************\n",
      "*                                                                                            *\n",
      "*     24m 22s Make repo [parallels]                                                          *\n",
      "*                                                                                            *\n",
      "**********************************************************************************************\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------\n",
      "-     24m 22s Run notebook [parallels/parallels] with parameters:                            -\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "|     24m 22s \tCORE_NAME            = bhsa\n",
      "|     24m 22s \tDO_VOCALIZED_LEXEME  = True\n",
      "|     24m 22s \tEXTRA_OVERLAP        = \n",
      "|     24m 22s \tFORCE_MATRIX         = False\n",
      "|     24m 22s \tLANG_FEATURE         = languageISO\n",
      "|     24m 22s \tLEX_FEATURE          = lex\n",
      "|     24m 22s \tLEX_FORMATS          = @fmt:lex-default={voc_lex_utf8} \n",
      "|     24m 22s \tOCC_FEATURE          = g_cons\n",
      "|     24m 22s \tRENAME               = (('g_suffix', 'trailer'), ('g_suffix_utf8', 'trailer_utf8'))\n",
      "|     24m 22s \tTEXT_FEATURE         = g_word_utf8\n",
      "|     24m 22s \tTRAILER_FEATURE      = trailer_utf8\n",
      "|     24m 22s \tVERSION              = 2021\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "|     24m 25s \tDestination /Users/werk/github/etcbc/parallels/tf/2021/.tf/crossref.tfx does not exist\n",
      "..............................................................................................\n",
      ".     24m 25s Load the existing TF dataset                                                   .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 9.1.7\n",
      "Api reference : https://annotation.github.io/text-fabric/tf/cheatsheet.html\n",
      "\n",
      "114 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s Dataset without structure sections in otext:no structure functions in the T-API\n",
      "    27s All features loaded/computed - for details use TF.isLoaded()\n",
      "..............................................................................................\n",
      ".     24m 52s CROSSREFS: Fetching crossrefs                                                  .\n",
      "..............................................................................................\n",
      "|     24m 52s \tReading existing /Users/werk/github/etcbc/parallels/_temp/parallelTable.tsv\n",
      "|     24m 52s \t\tINFO: All verse nodes are the same as in the previous version\n",
      "..............................................................................................\n",
      ".     24m 52s Writing TF parallel features                                                   .\n",
      "..............................................................................................\n",
      "|     24m 52s Compiled 31742 cross references into 6215 notes\n",
      "|     24m 53s Generated 6215 notes\n",
      "..............................................................................................\n",
      ".     24m 53s Check differences with previous version                                        .\n",
      "..............................................................................................\n",
      "|     24m 53s \tno features to add\n",
      "|     24m 53s \tno features to delete\n",
      "|     24m 53s \t3 features in common\n",
      "|     24m 53s crossref                  ... no changes\n",
      "|     24m 53s crossrefLCS               ... no changes\n",
      "|     24m 53s crossrefSET               ... no changes\n",
      "|     24m 53s Done\n",
      "..............................................................................................\n",
      ".     24m 53s Deliver data set to /Users/werk/github/etcbc/parallels/tf/2021                 .\n",
      "..............................................................................................\n",
      "..............................................................................................\n",
      ".     24m 53s Load and compile the new TF features                                           .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 9.1.7\n",
      "Api reference : https://annotation.github.io/text-fabric/tf/cheatsheet.html\n",
      "\n",
      "117 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s Dataset without structure sections in otext:no structure functions in the T-API\n",
      "   |     0.06s T crossref             from ~/github/etcbc/parallels/tf/2021\n",
      "   |     0.04s T crossrefLCS          from ~/github/etcbc/parallels/tf/2021\n",
      "   |     0.03s T crossrefSET          from ~/github/etcbc/parallels/tf/2021\n",
      "    21s All features loaded/computed - for details use TF.isLoaded()\n",
      "..............................................................................................\n",
      ".     25m 14s Test: crossrefs of Genesis 10                                                  .\n",
      "..............................................................................................\n",
      "|     25m 14s \tMethod \n",
      "|     25m 14s \t\t20 start verses\n",
      "\t\tGenesis 10:2\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:5     confidende 100%\n",
      "\t\tGenesis 10:3\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:6     confidende  95%\n",
      "\t\tGenesis 10:4\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:7     confidende  95%\n",
      "\t\tGenesis 10:6\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:8     confidende 100%\n",
      "\t\tGenesis 10:7\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:9     confidende 100%\n",
      "\t\tGenesis 10:8\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:10    confidende 100%\n",
      "\t\tGenesis 10:13\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:11    confidende 100%\n",
      "\t\tGenesis 10:14\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:12    confidende 100%\n",
      "\t\tGenesis 10:15\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:13    confidende 100%\n",
      "\t\tGenesis 10:16\n",
      "|     25m 14s \t\t         ----------> Genesis 15:21        confidende  83%\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:14    confidende 100%\n",
      "\t\tGenesis 10:17\n",
      "|     25m 14s \t\t         ----------> Genesis 15:20        confidende  76%\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:15    confidende 100%\n",
      "\t\tGenesis 10:20\n",
      "|     25m 14s \t\t         ----------> Genesis 10:31        confidende  87%\n",
      "\t\tGenesis 10:22\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:17    confidende  77%\n",
      "\t\tGenesis 10:24\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:18    confidende 100%\n",
      "\t\tGenesis 10:25\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:19    confidende 100%\n",
      "\t\tGenesis 10:26\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:20    confidende 100%\n",
      "\t\tGenesis 10:27\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:21    confidende 100%\n",
      "|     25m 14s \t\t         ----------> 2_Chronicles 11:9    confidende  78%\n",
      "\t\tGenesis 10:28\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:22    confidende 100%\n",
      "\t\tGenesis 10:29\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:23    confidende 100%\n",
      "\t\tGenesis 10:31\n",
      "|     25m 14s \t\t         ----------> Genesis 10:20        confidende  87%\n",
      "|     25m 14s \tMethod SET\n",
      "|     25m 14s \t\t20 start verses\n",
      "\t\tGenesis 10:2\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:5     confidende 100%\n",
      "\t\tGenesis 10:3\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:6     confidende  95%\n",
      "\t\tGenesis 10:4\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:7     confidende  95%\n",
      "\t\tGenesis 10:6\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:8     confidende 100%\n",
      "\t\tGenesis 10:7\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:9     confidende 100%\n",
      "\t\tGenesis 10:8\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:10    confidende 100%\n",
      "\t\tGenesis 10:13\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:11    confidende 100%\n",
      "\t\tGenesis 10:14\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:12    confidende 100%\n",
      "\t\tGenesis 10:15\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:13    confidende 100%\n",
      "\t\tGenesis 10:16\n",
      "|     25m 14s \t\t         ----------> Genesis 15:21        confidende  83%\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:14    confidende 100%\n",
      "\t\tGenesis 10:17\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:15    confidende 100%\n",
      "\t\tGenesis 10:20\n",
      "|     25m 14s \t\t         ----------> Genesis 10:31        confidende  80%\n",
      "\t\tGenesis 10:22\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:17    confidende  77%\n",
      "\t\tGenesis 10:24\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:18    confidende 100%\n",
      "\t\tGenesis 10:25\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:19    confidende 100%\n",
      "\t\tGenesis 10:26\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:20    confidende 100%\n",
      "\t\tGenesis 10:27\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:21    confidende 100%\n",
      "\t\tGenesis 10:28\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:22    confidende 100%\n",
      "\t\tGenesis 10:29\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:23    confidende 100%\n",
      "\t\tGenesis 10:31\n",
      "|     25m 14s \t\t         ----------> Genesis 10:20        confidende  80%\n",
      "|     25m 14s \tMethod LCS\n",
      "|     25m 14s \t\t20 start verses\n",
      "\t\tGenesis 10:2\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:5     confidende 100%\n",
      "\t\tGenesis 10:3\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:6     confidende  95%\n",
      "\t\tGenesis 10:4\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:7     confidende  95%\n",
      "\t\tGenesis 10:6\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:8     confidende 100%\n",
      "\t\tGenesis 10:7\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:9     confidende 100%\n",
      "\t\tGenesis 10:8\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:10    confidende 100%\n",
      "\t\tGenesis 10:13\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:11    confidende 100%\n",
      "\t\tGenesis 10:14\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:12    confidende 100%\n",
      "\t\tGenesis 10:15\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:13    confidende 100%\n",
      "\t\tGenesis 10:16\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:14    confidende 100%\n",
      "\t\tGenesis 10:17\n",
      "|     25m 14s \t\t         ----------> Genesis 15:20        confidende  76%\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:15    confidende 100%\n",
      "\t\tGenesis 10:20\n",
      "|     25m 14s \t\t         ----------> Genesis 10:31        confidende  94%\n",
      "\t\tGenesis 10:22\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:17    confidende  77%\n",
      "\t\tGenesis 10:24\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:18    confidende 100%\n",
      "\t\tGenesis 10:25\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:19    confidende 100%\n",
      "\t\tGenesis 10:26\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:20    confidende 100%\n",
      "\t\tGenesis 10:27\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:21    confidende 100%\n",
      "|     25m 14s \t\t         ----------> 2_Chronicles 11:9    confidende  78%\n",
      "\t\tGenesis 10:28\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:22    confidende 100%\n",
      "\t\tGenesis 10:29\n",
      "|     25m 14s \t\t         ----------> 1_Chronicles 1:23    confidende 100%\n",
      "\t\tGenesis 10:31\n",
      "|     25m 14s \t\t         ----------> Genesis 10:20        confidende  94%\n",
      "|     25m 14s SUCCESS parallels\n",
      "\n",
      "----------------------------------------------------------------------------------------------\n",
      "-     25m 14s SUCCES [parallels/parallels]                                                   -\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "**********************************************************************************************\n",
      "*                                                                                            *\n",
      "*     25m 14s SUCCES [parallels]                                                             *\n",
      "*                                                                                            *\n",
      "**********************************************************************************************\n",
      "\n",
      "\n",
      "**********************************************************************************************\n",
      "*                                                                                            *\n",
      "*     25m 14s Make repo [bridging]                                                           *\n",
      "*                                                                                            *\n",
      "**********************************************************************************************\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------\n",
      "-     25m 14s Run notebook [bridging/BHSAbridgeOSM] with parameters:                         -\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "|     25m 14s \tCORE_NAME            = bhsa\n",
      "|     25m 14s \tDO_VOCALIZED_LEXEME  = True\n",
      "|     25m 14s \tEXTRA_OVERLAP        = \n",
      "|     25m 14s \tLANG_FEATURE         = languageISO\n",
      "|     25m 14s \tLEX_FEATURE          = lex\n",
      "|     25m 14s \tLEX_FORMATS          = @fmt:lex-default={voc_lex_utf8} \n",
      "|     25m 14s \tOCC_FEATURE          = g_cons\n",
      "|     25m 14s \tRENAME               = (('g_suffix', 'trailer'), ('g_suffix_utf8', 'trailer_utf8'))\n",
      "|     25m 14s \tTEXT_FEATURE         = g_word_utf8\n",
      "|     25m 14s \tTRAILER_FEATURE      = trailer_utf8\n",
      "|     25m 14s \tVERSION              = 2021\n",
      "|     25m 15s \tDestination /Users/werk/github/etcbc/bridging/tf/2021/.tf/osm.tfx does not exist\n",
      "..............................................................................................\n",
      ".     25m 15s Load the existing TF dataset                                                   .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 9.1.7\n",
      "Api reference : https://annotation.github.io/text-fabric/tf/cheatsheet.html\n",
      "\n",
      "114 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s Dataset without structure sections in otext:no structure functions in the T-API\n",
      "    22s All features loaded/computed - for details use TF.isLoaded()\n",
      "|     25m 36s Genesis Exodus Leviticus Numeri Deuteronomium Josua Judices Samuel_I Samuel_II Reges_I Reges_II Jesaia Jeremia Ezechiel Hosea Joel Amos Obadia Jona Micha Nahum Habakuk Zephania Haggai Sacharia Maleachi Psalmi Iob Proverbia Ruth Canticum Ecclesiastes Threni Esther Daniel Esra Nehemia Chronica_I Chronica_II\n",
      "|     25m 36s 1Chr 1Kgs 1Sam 2Chr 2Kgs 2Sam Amos Dan Deut Eccl Esth Exod Ezek Ezra Gen Hab Hag Hos Isa Jer Job Joel Jonah Josh Judg Lam Lev Mal Mic Nah Neh Num Obad Prov Ps Ruth Song Zech Zeph\n",
      "|     25m 36s reading Gen   (Genesis        )  50 chapters\n",
      "|     25m 37s reading Exod  (Exodus         )  40 chapters\n",
      "|     25m 37s reading Lev   (Leviticus      )  27 chapters\n",
      "|     25m 37s reading Num   (Numeri         )  36 chapters\n",
      "|     25m 37s reading Deut  (Deuteronomium  )  34 chapters\n",
      "|     25m 37s reading Josh  (Josua          )  24 chapters\n",
      "|     25m 37s reading Judg  (Judices        )  21 chapters\n",
      "|     25m 38s reading 1Sam  (Samuel_I       )  31 chapters\n",
      "|     25m 38s reading 2Sam  (Samuel_II      )  24 chapters\n",
      "|     25m 38s reading 1Kgs  (Reges_I        )  22 chapters\n",
      "|     25m 38s reading 2Kgs  (Reges_II       )  25 chapters\n",
      "|     25m 38s reading Isa   (Jesaia         )  66 chapters\n",
      "|     25m 38s reading Jer   (Jeremia        )  52 chapters\n",
      "|     25m 39s reading Ezek  (Ezechiel       )  48 chapters\n",
      "|     25m 39s reading Hos   (Hosea          )  14 chapters\n",
      "|     25m 39s reading Joel  (Joel           )   4 chapters\n",
      "|     25m 39s reading Amos  (Amos           )   9 chapters\n",
      "|     25m 39s reading Obad  (Obadia         )   1 chapters\n",
      "|     25m 39s reading Jonah (Jona           )   4 chapters\n",
      "|     25m 39s reading Mic   (Micha          )   7 chapters\n",
      "|     25m 39s reading Nah   (Nahum          )   3 chapters\n",
      "|     25m 39s reading Hab   (Habakuk        )   3 chapters\n",
      "|     25m 39s reading Zeph  (Zephania       )   3 chapters\n",
      "|     25m 39s reading Hag   (Haggai         )   2 chapters\n",
      "|     25m 39s reading Zech  (Sacharia       )  14 chapters\n",
      "|     25m 39s reading Mal   (Maleachi       )   3 chapters\n",
      "|     25m 39s reading Ps    (Psalmi         ) 150 chapters\n",
      "|     25m 39s reading Job   (Iob            )  42 chapters\n",
      "|     25m 39s reading Prov  (Proverbia      )  31 chapters\n",
      "|     25m 39s reading Ruth  (Ruth           )   4 chapters\n",
      "|     25m 39s reading Song  (Canticum       )   8 chapters\n",
      "|     25m 39s reading Eccl  (Ecclesiastes   )  12 chapters\n",
      "|     25m 39s reading Lam   (Threni         )   5 chapters\n",
      "|     25m 39s reading Esth  (Esther         )  10 chapters\n",
      "|     25m 39s reading Dan   (Daniel         )  12 chapters\n",
      "|     25m 40s reading Ezra  (Esra           )  10 chapters\n",
      "|     25m 40s reading Neh   (Nehemia        )  13 chapters\n",
      "|     25m 40s reading 1Chr  (Chronica_I     )  29 chapters\n",
      "|     25m 40s reading 2Chr  (Chronica_II    )  36 chapters\n",
      "|     25m 40s \n",
      "BHS words:       426590\n",
      "OSM Morphemes:   469440\n",
      "No morphology:        1\n",
      "No content:           1\n",
      "100 % of the words are morphologically annotated.\n",
      "\n",
      "|     25m 42s Succeeded in aligning BHS with OSM\n",
      "|     25m 42s 420109 BHS words matched against 469440 OSM morphemes with 8 known exceptions\n",
      "|     25m 46s 469440 morphemes mapped in bhsFromOsm\n",
      "|     25m 46s OSM morphemes without corresponding BHSA word:                    0\n",
      "|     25m 46s OSM morphemes corresponding to multiple BHSA words:             122\n",
      "|     25m 46s OSM morphemes corresponding to 2 BHSA words:                    115\n",
      "|     25m 46s OSM morphemes corresponding to 3 BHSA words:                      7\n",
      "|     25m 48s insane BHS words:        6\n",
      "|     25m 48s insane OSM morphemes:    8\n",
      "|     25m 48s  1 morphemes per word: 370680\n",
      "|     25m 48s  2 morphemes per word:  49400\n",
      "|     25m 48s  3 morphemes per word:     27\n",
      "|     25m 48s  4 morphemes per word:      2\n",
      "|     25m 48s There are 259 problematic words in the BHSA wrt to OSM\n",
      "|     25m 48s These will be excluded from further comparisons\n",
      "|     25m 48s There is OSM morphology for all non-empty BHSA words\n",
      "|     25m 48s no non-marked-up stretches\n",
      "..............................................................................................\n",
      ".     25m 48s Writing tree feature to TF                                                     .\n",
      "..............................................................................................\n",
      "..............................................................................................\n",
      ".     25m 49s Check differences with previous version                                        .\n",
      "..............................................................................................\n",
      "|     25m 49s \tno features to add\n",
      "|     25m 49s \tno features to delete\n",
      "|     25m 49s \t2 features in common\n",
      "|     25m 49s osm                       ... no changes\n",
      "|     25m 49s osm_sf                    ... no changes\n",
      "|     25m 49s Done\n",
      "..............................................................................................\n",
      ".     25m 49s Deliver data set to /Users/werk/github/etcbc/bridging/tf/2021                  .\n",
      "..............................................................................................\n",
      "..............................................................................................\n",
      ".     25m 49s Load and compile the new TF features                                           .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 9.1.7\n",
      "Api reference : https://annotation.github.io/text-fabric/tf/cheatsheet.html\n",
      "\n",
      "116 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s Dataset without structure sections in otext:no structure functions in the T-API\n",
      "   |     0.73s T osm                  from ~/github/etcbc/bridging/tf/2021\n",
      "   |     0.11s T osm_sf               from ~/github/etcbc/bridging/tf/2021\n",
      "    17s All features loaded/computed - for details use TF.isLoaded()\n",
      "..............................................................................................\n",
      ".     26m 06s Basic tests                                                                    .\n",
      "..............................................................................................\n",
      "..............................................................................................\n",
      ".     26m 06s Language according to BHSA and OSM                                             .\n",
      "..............................................................................................\n",
      "|     26m 06s No other languages encountered than A, H\n",
      "|     26m 06s Language discrepancies: 2\n",
      "|     26m 06s Psalms 116:12 word 330987:         - BHSA: Aramaic; OSM: Hebrew\n",
      "|     26m 06s Psalms 116:12 word 330988:  - BHSA: Aramaic; OSM: Hebrew\n",
      "|     26m 06s SUCCESS BHSAbridgeOSM\n",
      "\n",
      "----------------------------------------------------------------------------------------------\n",
      "-     26m 06s SUCCES [bridging/BHSAbridgeOSM]                                                -\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "**********************************************************************************************\n",
      "*                                                                                            *\n",
      "*     26m 06s SUCCES [bridging]                                                              *\n",
      "*                                                                                            *\n",
      "**********************************************************************************************\n",
      "\n",
      "\n",
      "**********************************************************************************************\n",
      "*                                                                                            *\n",
      "*     26m 06s Make repo [trees]                                                              *\n",
      "*                                                                                            *\n",
      "**********************************************************************************************\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------\n",
      "-     26m 06s Run notebook [trees/trees] with parameters:                                    -\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "|     26m 06s \tCORE_NAME            = bhsa\n",
      "|     26m 06s \tDO_VOCALIZED_LEXEME  = True\n",
      "|     26m 06s \tEXTRA_OVERLAP        = \n",
      "|     26m 06s \tLANG_FEATURE         = languageISO\n",
      "|     26m 06s \tLEX_FEATURE          = lex\n",
      "|     26m 06s \tLEX_FORMATS          = @fmt:lex-default={voc_lex_utf8} \n",
      "|     26m 06s \tOCC_FEATURE          = g_cons\n",
      "|     26m 06s \tRENAME               = (('g_suffix', 'trailer'), ('g_suffix_utf8', 'trailer_utf8'))\n",
      "|     26m 06s \tTEXT_FEATURE         = g_word_utf8\n",
      "|     26m 06s \tTRAILER_FEATURE      = trailer_utf8\n",
      "|     26m 06s \tVERSION              = 2021\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "|     26m 07s \tDestination /Users/werk/github/etcbc/trees/tf/2021/.tf/tree.tfx does not exist\n",
      "..............................................................................................\n",
      ".     26m 07s Load the existing TF dataset                                                   .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 9.1.7\n",
      "Api reference : https://annotation.github.io/text-fabric/tf/cheatsheet.html\n",
      "\n",
      "114 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s Dataset without structure sections in otext:no structure functions in the T-API\n",
      "    30s All features loaded/computed - for details use TF.isLoaded()\n",
      "  0.00s loading features ...\n",
      "  0.08s All additional features loaded - for details use TF.isLoaded()\n",
      "  0.08s Start computing parent and children relations for objects of type sentence, clause, phrase, subphrase, word\n",
      "  0.36s 100000 nodes\n",
      "  0.65s 200000 nodes\n",
      "  0.92s 300000 nodes\n",
      "  1.20s 400000 nodes\n",
      "  1.47s 500000 nodes\n",
      "  1.74s 600000 nodes\n",
      "  2.01s 700000 nodes\n",
      "  2.30s 800000 nodes\n",
      "  2.58s 900000 nodes\n",
      "  2.70s 945491 nodes: 881774 have parents and 518901 have children\n",
      "  2.70s Restructuring clauses: deep copying tree relations\n",
      "  4.44s Pass 0: Storing mother relationship\n",
      "  4.49s 20791 clauses have a mother\n",
      "  4.49s All clauses have mothers of types in {'clause', 'sentence', 'subphrase', 'word', 'phrase'}\n",
      "  4.49s Pass 1: all clauses except those of type Coor\n",
      "  4.53s Pass 2: clauses of type Coor only\n",
      "  4.56s Mothers applied. Found 0 motherless clauses.\n",
      "  4.56s 3233 nodes have 1 sisters\n",
      "  4.56s 200 nodes have 2 sisters\n",
      "  4.56s 9 nodes have 3 sisters\n",
      "  4.56s There are 3660 sisters, 3442 nodes have sisters.\n",
      "..............................................................................................\n",
      ".     26m 42s Ready for processing                                                           .\n",
      "..............................................................................................\n",
      "..............................................................................................\n",
      ".     26m 42s Verifying whether all slots are preserved under restructuring                  .\n",
      "..............................................................................................\n",
      "..............................................................................................\n",
      ".     26m 42s Expected mismatches: ??                                                        .\n",
      "..............................................................................................\n",
      "..............................................................................................\n",
      ".     26m 44s 0 mismatches                                                                   .\n",
      "..............................................................................................\n",
      "..............................................................................................\n",
      ".     26m 44s Exporting sentence trees to TF                                                 .\n",
      "..............................................................................................\n",
      "|     26m 45s 10000 trees composed\n",
      "|     26m 46s 20000 trees composed\n",
      "|     26m 48s 30000 trees composed\n",
      "|     26m 49s 40000 trees composed\n",
      "|     26m 50s 50000 trees composed\n",
      "|     26m 52s 60000 trees composed\n",
      "..............................................................................................\n",
      ".     26m 52s 63717 trees composed                                                           .\n",
      "..............................................................................................\n",
      "..............................................................................................\n",
      ".     26m 52s Writing tree feature to TF                                                     .\n",
      "..............................................................................................\n",
      "..............................................................................................\n",
      ".     26m 52s Check differences with previous version                                        .\n",
      "..............................................................................................\n",
      "|     26m 52s \tno features to add\n",
      "|     26m 52s \tno features to delete\n",
      "|     26m 52s \t2 features in common\n",
      "|     26m 52s tree                      ... no changes\n",
      "|     26m 52s treen                     ... no changes\n",
      "|     26m 52s Done\n",
      "..............................................................................................\n",
      ".     26m 52s Deliver data set to /Users/werk/github/etcbc/trees/tf/2021                     .\n",
      "..............................................................................................\n",
      "..............................................................................................\n",
      ".     26m 52s Load and compile the new TF features                                           .\n",
      "..............................................................................................\n",
      "This is Text-Fabric 9.1.7\n",
      "Api reference : https://annotation.github.io/text-fabric/tf/cheatsheet.html\n",
      "\n",
      "116 features found and 0 ignored\n",
      "  0.00s loading features ...\n",
      "   |     0.00s Dataset without structure sections in otext:no structure functions in the T-API\n",
      "   |     0.20s T tree                 from ~/github/etcbc/trees/tf/2021\n",
      "   |     0.28s T treen                from ~/github/etcbc/trees/tf/2021\n",
      "    23s All features loaded/computed - for details use TF.isLoaded()\n",
      "..............................................................................................\n",
      ".     27m 15s Basic tests                                                                    .\n",
      "..............................................................................................\n",
      "..............................................................................................\n",
      ".     27m 15s Sample sentences in tree form                                                  .\n",
      "..............................................................................................\n",
      "|     27m 15s (S(C(PP(pp 0)(n 1))(VP(vb 2))(NP(n 3))(PP(U(pp 4)(dt 5)(n 6))(cj 7)(U(pp 8)(dt 9)(n 10)))))\n",
      "|     27m 15s (S(C(VP(vb 0))(NP(n 1))))\n",
      "|     27m 15s (S(C(CP(cj 0))(VP(vb 1))))\n",
      "|     27m 15s (S{1172308}(C{427559}(PP{651573}(pp 0)(n 1))(VP{651574}(vb 2))(NP{651575}(n 3))(PP{651576}(U{1300539}(pp 4)(dt 5)(n 6))(cj 7)(U{1300540}(pp 8)(dt 9)(n 10)))))\n",
      "|     27m 15s (S{1204166}(C{471249}(VP{782581}(vb 0))(NP{782582}(n 1))))\n",
      "|     27m 15s (S{1236024}(C{515689}(CP{904774}(cj 0))(VP{904775}(vb 1))))\n",
      "|     27m 15s SUCCESS trees\n",
      "\n",
      "----------------------------------------------------------------------------------------------\n",
      "-     27m 15s SUCCES [trees/trees]                                                           -\n",
      "----------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "**********************************************************************************************\n",
      "*                                                                                            *\n",
      "*     27m 15s SUCCES [trees]                                                                 *\n",
      "*                                                                                            *\n",
      "**********************************************************************************************\n",
      "\n",
      "\n",
      "##############################################################################################\n",
      "#                                                                                            #\n",
      "#     27m 15s SUCCES [2021]                                                                  #\n",
      "#                                                                                            #\n",
      "##############################################################################################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# good = runPipeline(pipeline, versions=['3', '4', '4b', '2016', '2017', 'c'], force=True)\n",
    "# good = runPipeline(pipeline, versions=['2016', '2017', 'c'], force=True)\n",
    "# good = runPipeline(pipeline, versions=[\"2021\"], repos=[\"bridging\", \"trees\"], force=False)\n",
    "good = runPipeline(pipeline, versions=[\"2021\"], repos=[\"valence\", \"parallels\", \"trees\", \"bridging\"], force=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# End of pipeline\n",
    "\n",
    "You might want to create the version mappings between recent versions.\n",
    "See the etcbc/bhsa/programs/versionMappings notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# What follows is legacy stuff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Consolidate the continuous version\n",
    "\n",
    "Previously, version `c` acted as a *continuous* version. The idea was that it would be overwritten\n",
    "by new snapshots of the data on a regular basis.\n",
    "\n",
    "We do not do that anymore, so the following steps are no longer relevant.\n",
    "\n",
    "Version `c` will be inactivated.\n",
    "\n",
    "Each version is a fixed version.\n",
    "\n",
    "We support the following workflow to carry out these updates:\n",
    "\n",
    "1. make a new version called `_temp`. Note:\n",
    "   * this choice of name prevents it to reach GitHub, because `_temp` directories are in `.gitignore`;\n",
    "   * after running this workflow, the version `_temp` already exists, this is not a problem;\n",
    "2. put a new data snapshot in the `source/_temp` directory of the `bhsa` repo, add also data to the\n",
    "   `source/_temp` directories of the other repos in the pipeline, as far as relevant;\n",
    "3. run `good = runPipeline(pipeline, versions=['_temp'], force=True)`. Note:\n",
    "   * we use `force=True` here, because then the old data in version `_temp` will be thoroughly overwritten;\n",
    "4. if all went well run `copyVersion(pipeline, '_temp', 'c')`. This will overwrite all data directories\n",
    "   in version `c` by the just created data directories in `temp`.\n",
    "\n",
    "If you have run an update version called `_temp`, and all has went well\n",
    "you can copy over the entire version (including its source and temp directories to `c`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##############################################################################################\n",
      "#                                                                                            #\n",
      "#     14m 41s Copy version _temp ==> c                                                       #\n",
      "#                                                                                            #\n",
      "##############################################################################################\n",
      "\n",
      "\n",
      "**********************************************************************************************\n",
      "*                                                                                            *\n",
      "*     14m 41s Repo bhsa                                                                      *\n",
      "*                                                                                            *\n",
      "**********************************************************************************************\n",
      "\n",
      "|     14m 41s \tCopy source/_temp ==> source/c\n",
      "|     14m 41s \t\tremoving existing source/c\n",
      "|     14m 41s \t\tputting data in place from source/_temp\n",
      "|     14m 42s \tCopy _temp/_temp ==> _temp/c\n",
      "|     14m 42s \t\tremoving existing _temp/c\n",
      "|     14m 42s \t\tputting data in place from _temp/_temp\n",
      "|     14m 47s \tCopy tf/_temp ==> tf/c\n",
      "|     14m 47s \t\tremoving existing tf/c\n",
      "|     14m 47s \t\tputting data in place from tf/_temp\n",
      "|     14m 51s \t\tadapting version in metadata of tf features to c\n",
      "|     15m 08s \tCopy shebanq/_temp ==> shebanq/c\n",
      "|     15m 08s \t\tno existing shebanq/c\n",
      "|     15m 08s \t\tNo data found in shebanq/_temp\n",
      "\n",
      "**********************************************************************************************\n",
      "*                                                                                            *\n",
      "*     15m 08s Repo phono                                                                     *\n",
      "*                                                                                            *\n",
      "**********************************************************************************************\n",
      "\n",
      "|     15m 08s \tCopy _temp/_temp ==> _temp/c\n",
      "|     15m 08s \t\tno existing _temp/c\n",
      "|     15m 08s \t\tputting data in place from _temp/_temp\n",
      "|     15m 08s \tCopy tf/_temp ==> tf/c\n",
      "|     15m 08s \t\tremoving existing tf/c\n",
      "|     15m 08s \t\tputting data in place from tf/_temp\n",
      "|     15m 08s \t\tadapting version in metadata of tf features to c\n",
      "\n",
      "**********************************************************************************************\n",
      "*                                                                                            *\n",
      "*     15m 09s Repo valence                                                                   *\n",
      "*                                                                                            *\n",
      "**********************************************************************************************\n",
      "\n",
      "|     15m 09s \tCopy source/_temp ==> source/c\n",
      "|     15m 09s \t\tremoving existing source/c\n",
      "|     15m 09s \t\tputting data in place from source/_temp\n",
      "|     15m 11s \tCopy _temp/_temp ==> _temp/c\n",
      "|     15m 11s \t\tno existing _temp/c\n",
      "|     15m 11s \t\tputting data in place from _temp/_temp\n",
      "|     15m 11s \tCopy tf/_temp ==> tf/c\n",
      "|     15m 11s \t\tremoving existing tf/c\n",
      "|     15m 11s \t\tputting data in place from tf/_temp\n",
      "|     15m 11s \t\tadapting version in metadata of tf features to c\n",
      "|     15m 12s \tCopy shebanq/_temp ==> shebanq/c\n",
      "|     15m 12s \t\tremoving existing shebanq/c\n",
      "|     15m 12s \t\tputting data in place from shebanq/_temp\n",
      "\n",
      "**********************************************************************************************\n",
      "*                                                                                            *\n",
      "*     15m 12s Repo parallels                                                                 *\n",
      "*                                                                                            *\n",
      "**********************************************************************************************\n",
      "\n",
      "|     15m 12s \tCopy source/_temp ==> source/c\n",
      "|     15m 12s \t\tno existing source/c\n",
      "|     15m 12s \t\tNo data found in source/_temp\n",
      "|     15m 12s \tCopy _temp/_temp ==> _temp/c\n",
      "|     15m 12s \t\tno existing _temp/c\n",
      "|     15m 12s \t\tputting data in place from _temp/_temp\n",
      "|     15m 12s \tCopy tf/_temp ==> tf/c\n",
      "|     15m 12s \t\tremoving existing tf/c\n",
      "|     15m 12s \t\tputting data in place from tf/_temp\n",
      "|     15m 12s \t\tadapting version in metadata of tf features to c\n"
     ]
    }
   ],
   "source": [
    "# good = True\n",
    "# good = False\n",
    "\n",
    "if good:\n",
    "    copyVersion(pipeline, \"_temp\", \"c\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
